[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608",
    "section": "",
    "text": "Welcome to Jin’s Analytics Journey!\n\nLet’s deep dive into what he has learnt in ISSS624 Geospatial Analytics Applications!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Note\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Note\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\n\n is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics\n\n\n\nIt is part of the tidyverse family specially designed for visual exploration and communication.\n\n\n\nFor more detail, visit ggplot2 link.\n\n\n1.3.1 R Graphics VS ggplot\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\nThen, why ggplot2\n\n\n\n\n\n\nNote\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.\n\n\nHadley Wickham"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\n\nWilkinson, L. (1999) Grammar of Graphics, Springer.\nThe grammar of graphics is an answer to a question:\n\n\nWhat is a statistical graphic?\n\n\nGrammar of graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978).\nA grammar provides a strong foundation for understanding a diverse range of graphics.\nA grammar may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics. :::\n\n\n1.4.1. R A Layered Grammar of Graphics\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\n\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\n\nLet us call the ggplot() function using the code chunk on the right.\n\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nNotice that a blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\n\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency.Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk on the right add the aesthetic element into the plot.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\nNote\n\n\n\n\nNotice that ggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include: ::: {style=“font-size: 0.8em”} - geom_point for drawing individual points (e.g., a scatter plot) - geom_line for drawing lines (e.g., for a line charts) - geom_smooth for drawing smoothed lines (e.g., for simple trends or approximations) - geom_bar for drawing bars (e.g., for bar charts) - geom_histogram for drawing binned values (e.g. a histogram) - geom_polygon for drawing arbitrary shapes - geom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function). :::\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\n1.7.1 Essential Grammatical Elements in ggplot2: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n1.7.2 Essential Grammatical Elements in ggplot2: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\nBe warned\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n1.7.3. Essential Grammatical Elements in ggplot2s: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n\n\n\n\n\n1.7.4. Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n\n\n\n\n\n1.7.6. Geometric Objects: geom-density\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\nReference: Kernel density estimation\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n1.7.7. Geometric Objects: geom-boxplot\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nThe code chunk below plots boxplots by using geom_boxplot().]\n\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\nReference: Notched Box Plots.\n\n\n\n\n\n\n\n1.7.8 Essential Grammatical Elements in ggplot2: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n1.7.9 Essential Grammatical Elements in ggplot2: geom_point()\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n1.7.10.1. Essential Grammatical Elements in ggplot2s: geom_violin() and geom_boxplot()\nThe code chunk below combined a violin plot and a boxplot to show the distribution of Maths scores by gender.]\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin(fill=\"light blue\") +\n  geom_boxplot(alpha=0.5)           \n\n\n\n\n\n\n\n\n1.7.10.2 Essential Grammatical Elements in ggplot2: geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +              #&lt;&lt;      \n  geom_point(position=\"jitter\", #&lt;&lt;\n             size = 0.5)        #&lt;&lt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8. Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8. Essential Grammatical Elements in ggplot2: stat\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\n\nThe boxplots on the right are incomplete because the positions of the means were not shown.\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n1.8.3. Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n1.8.4 How to add a best fit curve on a scatterplot?\n\nThe scatterplot on the right shows the relationship of Maths and English grades of pupils.\nThe interpretability of this graph can be improved by adding a best fit curve.\n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nThe default method used is loess.]\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "1.9. Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9. Essential Grammatical Elements in ggplot2: Facets\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data.\nFacets are an alternative to aesthetics for displaying additional discrete variables.\nggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\n1.9.1 Working with facet_wrap()\n\nfacet_wrap wraps a 1d sequence of panels into 2d.\nThis is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\n\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\nfacet_grid() function\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables.\nIt is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\n\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "1.10. Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10. Essential Grammatical Elements in ggplot2: Coordinates\n\nThe Coordinates functions map the position of objects onto the plane of the plot.\nThere are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n\n\n1.10.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n1.10.2 How to change to the y- and x-axis range?\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "1.11. Essential Grammatical Elements in ggplot2: Themes",
    "text": "1.11. Essential Grammatical Elements in ggplot2: Themes\nThemes control elements of the graph not related to the data. For example: ::: {style=“font-size: 0.8em”} - background colour - size of fonts - gridlines - colour of labels ::: Built-in themes include: - theme_gray() (default) - theme_bw() - theme_classic() A list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "1.12. Reference",
    "text": "1.12. Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "Note\n\n\n\nIn the code chunk, p_load() and pacman package is used to load tidyverse family of packages\n\n\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-packages",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "Note\n\n\n\nIn the code chunk, p_load() and pacman package is used to load tidyverse family of packages\n\n\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-data",
    "title": "In-class Exercise 01",
    "section": "Importing Data",
    "text": "Importing Data\n\nrealis &lt;-read_csv(\"data/realis2019.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#r-graphics-vs-ggplot",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#r-graphics-vs-ggplot",
    "title": "In-class Exercise 01",
    "section": "R Graphics vs GGplot",
    "text": "R Graphics vs GGplot\n\nggplot(data=realis, \n       aes(x = `Unit Price ($ psm)`)) +\n    geom_histogram()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-task",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-task",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "The Data",
    "text": "The Data\nTo accomplish the task, transaction data of REALIS will be used. A complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024 have been downloaded via SMU e-library database service."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#install-r-package",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#install-r-package",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Install R Package",
    "text": "Install R Package\n\npacman::p_load(tidyverse,forcats)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Importing Data",
    "text": "Importing Data\nWe will import the data as a first step before proceeding with data cleaning, data wrangling and data ex\n\n# Get list of CSV files in the directory\nfile_list &lt;- list.files(path = \"data\", pattern = \"*.csv\", full.names = TRUE)\n\n# Read and bind all CSV files into one data frame\ncombined_data &lt;- file_list %&gt;%\n  map_df(read_csv)\n\n# View the structure of the combined data\nstr(combined_data)\n\nspc_tbl_ [26,806 × 21] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:26806] \"THE REEF AT KING'S DOCK\" \"URBAN TREASURES\" \"NORTH GAIA\" \"NORTH GAIA\" ...\n $ Transacted Price ($)       : num [1:26806] 2317000 1823500 1421112 1258112 1280000 ...\n $ Area (SQFT)                : num [1:26806] 883 883 1076 1033 872 ...\n $ Unit Price ($ PSF)         : num [1:26806] 2625 2066 1320 1218 1468 ...\n $ Sale Date                  : chr [1:26806] \"01 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" ...\n $ Address                    : chr [1:26806] \"12 HARBOURFRONT AVENUE #05-32\" \"205 JALAN EUNOS #08-02\" \"29 YISHUN CLOSE #08-10\" \"45 YISHUN CLOSE #07-42\" ...\n $ Type of Sale               : chr [1:26806] \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr [1:26806] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num [1:26806] 82 82 100 96 81 ...\n $ Unit Price ($ PSM)         : num [1:26806] 28256 22238 14211 13105 15802 ...\n $ Nett Price($)              : chr [1:26806] \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr [1:26806] \"Condominium\" \"Condominium\" \"Executive Condominium\" \"Executive Condominium\" ...\n $ Number of Units            : num [1:26806] 1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr [1:26806] \"99 yrs from 12/01/2021\" \"Freehold\" \"99 yrs from 15/02/2021\" \"99 yrs from 15/02/2021\" ...\n $ Completion Date            : chr [1:26806] \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr [1:26806] \"HDB\" \"Private\" \"HDB\" \"HDB\" ...\n $ Postal Code                : chr [1:26806] \"097996\" \"419535\" \"269343\" \"269294\" ...\n $ Postal District            : chr [1:26806] \"04\" \"14\" \"27\" \"27\" ...\n $ Postal Sector              : chr [1:26806] \"09\" \"41\" \"26\" \"26\" ...\n $ Planning Region            : chr [1:26806] \"Central Region\" \"East Region\" \"North Region\" \"North Region\" ...\n $ Planning Area              : chr [1:26806] \"Bukit Merah\" \"Bedok\" \"Yishun\" \"Yishun\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `Project Name` = col_character(),\n  ..   `Transacted Price ($)` = col_number(),\n  ..   `Area (SQFT)` = col_number(),\n  ..   `Unit Price ($ PSF)` = col_number(),\n  ..   `Sale Date` = col_character(),\n  ..   Address = col_character(),\n  ..   `Type of Sale` = col_character(),\n  ..   `Type of Area` = col_character(),\n  ..   `Area (SQM)` = col_number(),\n  ..   `Unit Price ($ PSM)` = col_number(),\n  ..   `Nett Price($)` = col_character(),\n  ..   `Property Type` = col_character(),\n  ..   `Number of Units` = col_double(),\n  ..   Tenure = col_character(),\n  ..   `Completion Date` = col_character(),\n  ..   `Purchaser Address Indicator` = col_character(),\n  ..   `Postal Code` = col_character(),\n  ..   `Postal District` = col_character(),\n  ..   `Postal Sector` = col_character(),\n  ..   `Planning Region` = col_character(),\n  ..   `Planning Area` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n# View the first few rows of the combined data\nhead(combined_data)\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\nsummary(combined_data)\n\n Project Name       Transacted Price ($)  Area (SQFT)       Unit Price ($ PSF)\n Length:26806       Min.   :   440000    Min.   :   322.9   Min.   : 138      \n Class :character   1st Qu.:  1280000    1st Qu.:   721.2   1st Qu.:1384      \n Mode  :character   Median :  1660000    Median :   990.3   Median :1762      \n                    Mean   :  2143286    Mean   :  1191.6   Mean   :1852      \n                    3rd Qu.:  2320000    3rd Qu.:  1302.4   3rd Qu.:2260      \n                    Max.   :392180000    Max.   :144883.4   Max.   :5756      \n                                                                              \n  Sale Date           Address          Type of Sale       Type of Area      \n Length:26806       Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Area (SQM)      Unit Price ($ PSM) Nett Price($)      Property Type     \n Min.   :   30.0   Min.   : 1484      Length:26806       Length:26806      \n 1st Qu.:   67.0   1st Qu.:14893      Class :character   Class :character  \n Median :   92.0   Median :18966      Mode  :character   Mode  :character  \n Mean   :  110.5   Mean   :19930                                           \n 3rd Qu.:  121.0   3rd Qu.:24327                                           \n Max.   :13460.0   Max.   :61962                                           \n NA's   :6                                                                 \n Number of Units     Tenure          Completion Date   \n Min.   : 1.000   Length:26806       Length:26806      \n 1st Qu.: 1.000   Class :character   Class :character  \n Median : 1.000   Mode  :character   Mode  :character  \n Mean   : 1.005                                        \n 3rd Qu.: 1.000                                        \n Max.   :60.000                                        \n                                                       \n Purchaser Address Indicator Postal Code        Postal District   \n Length:26806                Length:26806       Length:26806      \n Class :character            Class :character   Class :character  \n Mode  :character            Mode  :character   Mode  :character  \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n Postal Sector      Planning Region    Planning Area     \n Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#missing-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#missing-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.2. Missing Data",
    "text": "2.2. Missing Data\n\n# Check for the rows with null values\nnull_check &lt;- combined_data %&gt;% \n                  filter(is.na(`Area (SQM)`))\nnull_check\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 CALDECOTT HILL ESTA…               22250000        10931.                 2036\n2 CALDECOTT HILL ESTA…               22000000        11083.                 1985\n3 RAFFLES PARK                       25300000        11071.                 2285\n4 BRADDELL HEIGHTS ES…               20300000        14274.                 1422\n5 JERVOISVILLE                       21020000        11642.                 1805\n6 N.A.                               16100000        14199.                 1134\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\nGiven the data above, it is impossible for us to understand if there is a systemic reason for the cause of missing data, hence we shall proceed to drop these rows from analysis.The current data now is reduced to 26800 observations from the initial 26806.\n\n# Filter out rows where `Area (SQM)` is not missing\ncombined_data &lt;- combined_data %&gt;% \n                  filter(!is.na(`Area (SQM)`))\n\nWe are not planning to utilise Completion Date, so we will not make any changes regarding that"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-type",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-type",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.3. Data Type",
    "text": "2.3. Data Type\nFrom the Data Exploration earlier, we found ‘Sale Date’ to be in chr format, we need to change it to date format to analyze the data properly.\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(`Sale Date` = as.Date(`Sale Date`, format = \"%d %b %Y\"))\n\n# View the structure of the modified data\nstr(combined_data)\n\ntibble [26,800 × 21] (S3: tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:26800] \"THE REEF AT KING'S DOCK\" \"URBAN TREASURES\" \"NORTH GAIA\" \"NORTH GAIA\" ...\n $ Transacted Price ($)       : num [1:26800] 2317000 1823500 1421112 1258112 1280000 ...\n $ Area (SQFT)                : num [1:26800] 883 883 1076 1033 872 ...\n $ Unit Price ($ PSF)         : num [1:26800] 2625 2066 1320 1218 1468 ...\n $ Sale Date                  : Date[1:26800], format: \"2023-01-01\" \"2023-01-02\" ...\n $ Address                    : chr [1:26800] \"12 HARBOURFRONT AVENUE #05-32\" \"205 JALAN EUNOS #08-02\" \"29 YISHUN CLOSE #08-10\" \"45 YISHUN CLOSE #07-42\" ...\n $ Type of Sale               : chr [1:26800] \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr [1:26800] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num [1:26800] 82 82 100 96 81 ...\n $ Unit Price ($ PSM)         : num [1:26800] 28256 22238 14211 13105 15802 ...\n $ Nett Price($)              : chr [1:26800] \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr [1:26800] \"Condominium\" \"Condominium\" \"Executive Condominium\" \"Executive Condominium\" ...\n $ Number of Units            : num [1:26800] 1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr [1:26800] \"99 yrs from 12/01/2021\" \"Freehold\" \"99 yrs from 15/02/2021\" \"99 yrs from 15/02/2021\" ...\n $ Completion Date            : chr [1:26800] \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr [1:26800] \"HDB\" \"Private\" \"HDB\" \"HDB\" ...\n $ Postal Code                : chr [1:26800] \"097996\" \"419535\" \"269343\" \"269294\" ...\n $ Postal District            : chr [1:26800] \"04\" \"14\" \"27\" \"27\" ...\n $ Postal Sector              : chr [1:26800] \"09\" \"41\" \"26\" \"26\" ...\n $ Planning Region            : chr [1:26800] \"Central Region\" \"East Region\" \"North Region\" \"North Region\" ...\n $ Planning Area              : chr [1:26800] \"Bukit Merah\" \"Bedok\" \"Yishun\" \"Yishun\" ...\n\n# View the first few rows of the modified data\nhead(combined_data)\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 17 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#duplicates-check",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#duplicates-check",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.4. Duplicates Check",
    "text": "2.4. Duplicates Check\nPassed initial checks in code chunk below for whole duplicate rows,\n\nduplicate &lt;- combined_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\nProceed to checking for duplicates in the Address column, we seemed to have found 9 duplicated observations. However, they have different \"Sale Date\". As this is expected, we will ignore the case of duplicate address found here and proceed ahead.\n\nduplicates &lt;- combined_data[duplicated(combined_data$Address), ]\nfiltered_data &lt;- combined_data[combined_data$Address %in% duplicates$Address, ]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel) \n\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment using read_csv() function of readr package.readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#content",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#content",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Beyond ggplot2 Themes\nBeyond ggplot2 Annotation\nBeyond ggplot2 facet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel) \n\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment using read_csv() function of readr package.readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 Annotation",
    "text": "Beyond ggplot2 Annotation\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with ggrepel\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right. We simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\n\nWorking with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, \n              base_size = 15, \n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk below?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 facet",
    "text": "Beyond ggplot2 facet\n\n\nIn this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics.\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "The Data",
    "text": "The Data\nTo accomplish the task, transaction data of REALIS will be used. A complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024 have been downloaded via SMU e-library database service."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-package",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-package",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Install R Package",
    "text": "Install R Package\n\npacman::p_load(tidyverse,ggrepel, patchwork, hrbrthemes, forcats,ggdist, ggridges,\n               ggthemes,colorspace,lubridate, cowplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 02",
    "section": "",
    "text": "Note\n\n\n\nIn the code chunk, p_load() and pacman package is used to load tidyverse family of packages\n\n\n\npacman::p_load(tidyverse, ggdist, ggthemes, colorspace, ggridges)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-packages",
    "title": "In-class Exercise 02",
    "section": "",
    "text": "Note\n\n\n\nIn the code chunk, p_load() and pacman package is used to load tidyverse family of packages\n\n\n\npacman::p_load(tidyverse, ggdist, ggthemes, colorspace, ggridges)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-data",
    "title": "In-class Exercise 02",
    "section": "Importing Data",
    "text": "Importing Data\n\nexam_df &lt;-read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#r-graphics-vs-ggplot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#r-graphics-vs-ggplot",
    "title": "In-class Exercise 01",
    "section": "R Graphics vs GGplot",
    "text": "R Graphics vs GGplot\n\nggplot(data=realis, \n       aes(x = `Unit Price ($ psm)`)) +\n    geom_histogram()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#histogram",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#histogram",
    "title": "In-class Exercise 02",
    "section": "Histogram",
    "text": "Histogram\n\nThe TaskThe Code\n\n\nUsing the step you learned , build a histogram\n\n\n\nggplot(data=exam_df, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of English scores\") +\n  theme_economist()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#distribution",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#distribution",
    "title": "In-class Exercise 02",
    "section": "Distribution",
    "text": "Distribution\n\nThe TaskThe Code\n\n\nUsing the step you learned , build a density plot\n\n\n\nggplot(data=exam_df, \n             aes(x = ENGLISH)) +\n  geom_density(color =\"#1696d2\",\n               adjust =0.65,\n               alpha =0.6)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-alternative-design",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-alternative-design",
    "title": "In-class Exercise 02",
    "section": "The alternative design",
    "text": "The alternative design\n\nThe TaskThe Code\n\n\nUsing the step you learned , build a density plot\n\n\n\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(data = exam_df, aes(x = ENGLISH)) +\n  geom_density(color = \"#1696d2\", adjust = 0.65, alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_eng, sd = std_eng),\n    col = \"grey30\",\n    size = 0.8\n  ) +\n  geom_vline(\n    aes(xintercept = mean_eng),\n    colour = \"#4d5887\",\n    linewidth = 0.6,\n    linetype = \"dashed\"\n  ) +\n  annotate(\n    geom = \"text\",\n    x = mean_eng - 14,\n    y = 0.03,\n    label = paste0(\"Mean ENGLISH: \", round(mean_eng, 2)),\n    color = \"#4d5887\"\n  ) +\n  geom_vline(\n    aes(xintercept = median_eng),\n    colour = \"#00AFBB\",\n    linewidth = 0.6,\n    linetype = \"dashed\"\n  ) +\n  annotate(\n    geom = \"text\",\n    x = mean_eng - 8,\n    y = 0.04,\n    label = paste0(\"Median ENGLISH: \", round(median_eng, 2)),\n    color = \"#00AFBB\"\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 Annotation: ggrepel",
    "text": "Beyond ggplot2 Annotation: ggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\nWorking with ggrepel\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "Beyond Single Graph",
    "text": "Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n2.5.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\np1 + p2\n\n\n\n\n\n\n2.5.3 Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\np1 + p2 / p3\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, left = 0.02, bottom = 0.7, right = 0.5, top = 1)\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork &\n  theme_economist() &\n  theme(plot.title = element_text(size=8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "2.6 Reference",
    "text": "2.6 Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "References",
    "text": "References\n\nWhy Does A Condo Have A Higher Price Per Square Foot Than A bungalow?"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-visualisation",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-visualisation",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "6.1. Data Visualisation",
    "text": "6.1. Data Visualisation\n\n\nShow the code\n# Plot a stacked bar chart for 'Apartment' sales\nstacked_bar &lt;- ggplot(purchaseindicator_allsales, aes(x = `Property Type`, y = Count, fill = `Purchaser Address Indicator`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = NULL, y = \"Count\", fill = \"Purchaser Address Indicator\") +\n  scale_fill_manual(values = c(\"Private\" = \"#1696d2\", \"HDB\" = \"#f8766d\")) +  # Adjust fill colors\n  theme_economist() +\n  theme(\n    legend.position = \"right\",  # Place legend on the right side\n    legend.direction = \"vertical\",  # Vertical legend\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 8, color = \"black\"),  # Adjust x-axis labels\n    axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)),  # Adjust y-axis title margin\n    plot.margin = margin(0.1, 0.5, 0, 0.5, \"cm\"),  # Set margins\n    panel.grid.major = element_blank(),  # Remove major gridlines\n    panel.grid.minor = element_blank(),  # Remove minor gridlines\n    panel.spacing = unit(0.01, \"lines\")\n  )\n\n# Print the stacked bar chart\nprint(stacked_bar)\n\n\n\n\n\nFrom our findings:\n\nMost of the HDB converters purchase Apartment, Condos and Executive Condos. Few purchased Detached , semi-Detached and Terrace Houses\nAlso, most of the house buyers are past private property owners with the exception for executive condos."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%  \n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet. mutate_each_() of dplyr package is used to convert all character data type into factor. mutate of dplyr package is used to convert data values of Year field into integer.\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%   \n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#overview",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#getting-started",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%  \n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet. mutate_each_() of dplyr package is used to convert all character data type into factor. mutate of dplyr package is used to convert data values of Year field into integer.\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\") \nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet = \"Data\") %&gt;%\n  mutate(across(all_of(col), as.factor)) %&gt;%   \n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young,size = Population, colour = Country)) +\ngeom_point(alpha = 0.7,show.legend = FALSE) + \n  scale_colour_manual(values = country_colors) + \n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', x = '% Aged', y = '% Young') \n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young,size = Population,colour = Country)) +\ngeom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) + \n  labs(title = 'Year: {frame_time}',x = '% Aged', y = '% Young')+\n  transition_time(Year) + \n  ease_aes('linear')          \n\n\n\n\nThe animated bubble chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg &lt;- ggplot(globalPop,aes(x = Old,y = Young,size = Population,colour = Country)) +   geom_point(aes(size = Population,  frame = Year), alpha = 0.7,show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) + \n  scale_size(range = c(2, 12)) + \n  labs(x = '% Aged', y = '% Young') \nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population,\n          color = ~Continent, \n          sizes = c(2, 100), \n          frame = ~Year,\n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers') %&gt;% \n  layout(showlegend = FALSE) \n\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#reference",
    "title": "Hands-on Exercise 3: Programming Animated Statistical Graphics with R",
    "section": "4.5 Reference",
    "text": "4.5 Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#getting-started",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly,patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#importing-data",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     #&lt;&lt;\n  \"Name = \", exam_data$ID,         #&lt;&lt;\n  \"\\n Class = \", exam_data$CLASS)) #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #&lt;&lt;\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  opti\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {   #&lt;&lt;\n  mean &lt;- scales::number(y, accuracy = accuracy) #&lt;&lt;\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy) #&lt;&lt;\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #&lt;&lt;\n} #&lt;&lt;\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #&lt;&lt;\n                     tooltip(y, ymax))),  #&lt;&lt;\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #&lt;&lt;\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #&lt;&lt;\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #&lt;&lt;\n    opts_hover(css = \"fill: #202020;\"),  #&lt;&lt;\n    opts_hover_inv(css = \"opacity:0.2;\") #&lt;&lt;\n  )                                      #&lt;&lt;  \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #&lt;&lt;\n        data_id = CLASS),#&lt;&lt;              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #&lt;&lt;\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n:::\nWarning\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #&lt;&lt;\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nThe output:\n\n\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #&lt;&lt;\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #&lt;&lt;\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)  #&lt;&lt;\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\n3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#reference",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "In this take-home exercise we are required to:\n\nSelect one data visualisation from the Take-home Exercise 1 submission prepared by your classmate,\nCritic the submission in terms of clarity and aesthetics, prepare a sketch for the alternative design by using the data visualisation design principles and best practices.\nRemake the original design by using ggplot2, ggplot2 extensions and tidyverse packages.\n\nFor this exercise, I have chosen our classmate ZOU JIAXUN’s visualization in his Take-home Exercise 1 submission to critique."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#original-design",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#original-design",
    "title": "Take Home Exercise 2",
    "section": "2.1 Original Design",
    "text": "2.1 Original Design\nFigure 1 below shows the original design of the Unit Price ($PSF) for Private Properties in Singapore during the first quarter of 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#critique-clarity-and-aesthetics",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#critique-clarity-and-aesthetics",
    "title": "Take Home Exercise 2",
    "section": "2.2 Critique: Clarity and Aesthetics",
    "text": "2.2 Critique: Clarity and Aesthetics\n\nClarity\n\nThis chart fails to demonstrate several observations made by our classmate:\n“…a clear disparity emerges between the average unit prices of condominiums and apartments, standing at approximately $1,500 and $2,000, respectively, for the period spanning January to March…”\n\nThe chart doesn’t provide clear information about the average unit prices of condominiums and apartments. The absence of labels, compounded by the use of a violin plot that highlights distribution, adds to the complexity.\n\n“…Noteworthy is the discernible uptick in both unit price and transaction volume from January to March 2024…”\n\nTransaction volume is particularly challenging to discern compared to unit price because the y-axis is focused on describing unit prices.\n\n“…Despite an overall reduction in total transactions vis-a-vis the preceding year, there is an unmistakable trend towards growth within specific sub-markets, suggesting an increasing inclination towards higher-value properties…”\n\nThe x-axis represents the three months of Q1 2024 instead of displaying transaction volume, a metric frequently referenced by the author. Utilizing the x-axis to depict transaction volume would enhance clarity significantly..\n\nOther concerns:\nThe title provides a general description but lacks specificity. It does not specify the time period covered by the visualization, nor does it offer insight into the context or main focus of the visualization. A more detailed title and subtitle would enhance clarity and understanding for the audience.\nThe x-axis represents the three months of Q1 2024 instead of displaying transaction volume, a metric frequently referenced by the author. Utilizing the x-axis to depict transaction volume would enhance clarity significantly.\n\n\n\nAesthetics\n\nThe color selection is problematic due to the light-colored background, which matches the hue of the violin plot. This makes it strenuous for the eyes to distinguish between elements.\nFonts, titles, x-ticks, and legends are small and difficult to discern."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#proposed-sketch",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#proposed-sketch",
    "title": "Take Home Exercise 2",
    "section": "3.1 Proposed Sketch",
    "text": "3.1 Proposed Sketch\nA violin is often not well understood by the general public. In this case, the use of a violin plot is worse as the writer intends to make several comparisons that are not obvious from said plot.\nThis scenario seems appropriate for a similar makeover done by Michael Djohan for another student.\nAcknowledging that point plots may distract and add little value, we omitted them. Instead, a modified bar chart resembling a violin plot was adopted. This alternative retains the visual appeal of a violin plot while providing clearer and more informative comparisons. We also decided to add annotations for median prices and transaction volume. A facet plot is used to distinctively compare between the three months for Q1 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-preparation",
    "title": "Take Home Exercise 2",
    "section": "3.2 Data Preparation",
    "text": "3.2 Data Preparation\nLet us first load the files and merge them into combined_data #Load packages\n\n\nShow the code\n#Load packages\npacman::p_load(cowplot, scales, patchwork, tidyverse)\n\n#Import data\nfile_list &lt;- list.files(path = \"data\", pattern = \"*.csv\", full.names = TRUE)\ncombined_data &lt;- file_list %&gt;%\n  map_df(read_csv)\n\n\n\nOriginal data preparation done by student\nIn this chunk of code, we adopted exactly similar modifications to the data to ensure perfect replication. Nothing new is added here.\nThe data preparation here involves:\n\nformatting the Sale Date column into Quarters and Months using the dmy() function from the lubridate package.\nRemoving NA Values\nFilter for Q1 2024 data only\nFilter for “Apartment” and “Condominium” only\n\n\n\nShow the code\n# filtering the data\nfiltered_data &lt;- combined_data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`)) %&gt;%\n  filter((year(Sale_Date) == 2023 & \n          month(Sale_Date) %in% 1:12) |\n         (year(Sale_Date) == 2024 & \n          month(Sale_Date) %in% 1:3)) %&gt;%\n  mutate(Quarter_Sale_Data = case_when(\n    between(Sale_Date, as.Date(\"2023-01-01\"), as.Date(\"2023-03-31\")) ~ \"Q1_2023\",\n    between(Sale_Date, as.Date(\"2023-04-01\"), as.Date(\"2023-06-30\")) ~ \"Q2_2023\",\n    between(Sale_Date, as.Date(\"2023-07-01\"), as.Date(\"2023-09-30\")) ~ \"Q3_2023\",\n    between(Sale_Date, as.Date(\"2023-10-01\"), as.Date(\"2023-12-31\")) ~ \"Q4_2023\",\n    between(Sale_Date, as.Date(\"2024-01-01\"), as.Date(\"2024-03-31\")) ~ \"Q1_2024\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Quarter_Sale_Data)) %&gt;%\n  filter(Quarter_Sale_Data == \"Q1_2024\") %&gt;%\n  mutate(Month_Sale_Data = paste0(year(Sale_Date), \"-\", month(Sale_Date))) \n\nfiltered_data &lt;- filtered_data %&gt;%\n  filter(`Property Type` %in% c(\"Apartment\", \"Condominium\"))\n\n\n\n\nModifying the prepared data\n\nBinning for Unit Price ($ PSF)\nFrom here on, we begin to make our own modifications which are plenty and necessary. Firstly, we realize that we construct our desired plot we need our Unit Price ($ PSF)to be categorized into bins as Unit_Price_Bin\n\n\nShow the code\n# Creating bins\nbreaks &lt;- c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250, 3500, 3750, 4000)\n\nfiltered_data &lt;- filtered_data %&gt;%\n  filter(!is.na(`Unit Price ($ PSF)`)) %&gt;%\n  filter(`Unit Price ($ PSF)` &lt;= 4000) %&gt;%\n  mutate(Unit_Price_Bin = cut(`Unit Price ($ PSF)`, \n                              breaks = breaks, \n                              labels = c(\"751-1000\", \"1001-1250\", \"1251-1500\", \"1501-1750\", \"1751-2000\", \"2001-2250\", \"2251-2500\", \"2501-2750\", \"2751-3000\", \"3001-3250\", \"3251-3500\", \"3501-3750\", \"3751-4000\"), \n                              include.lowest = TRUE,\n                              right = FALSE)) %&gt;%\n  filter(!is.na(Unit_Price_Bin))\n\n\nWe save our processed data into .rds data format files using the write_rds() of readr package. The output file is saved in rds sub-folder. We do this to reduce the loading time and more importantly, we can avoid uploading the large raw files onto GitHub.\n\nwrite_rds(filtered_data, \"data/rds/filtered_data.rds\")\nfiltered_data &lt;- read_rds(\"data/rds/filtered_data.rds\")\n\n\n\nBase Data Creation:\nThe code creates a base dataset (base_data) by grouping the filtered data (filtered_data) by month of sale, unit price bin, and property type. It calculates the count of transactions (Count) and assigns negative values to transactions related to apartments (Trans_Vol) to prepare for a pyramid chart.\n\n\nShow the code\n# Creating base data for pyramid\nbase_data &lt;- filtered_data %&gt;%\n  group_by(Month_Sale_Data, Unit_Price_Bin, `Property Type`) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(Trans_Vol = ifelse(`Property Type` == \"Apartment\", Count * (-1), Count))\n\n\n\n\nMedian Unit Price Calculation:\nIt computes the median unit price (median_unit_price) for each month and property type combination, adjusting the values for apartments to negative if necessary.\n\n\nShow the code\n# median Unit Price\nUnitPrice_median &lt;- filtered_data %&gt;%\n  group_by(Month_Sale_Data, `Property Type`) %&gt;%\n  summarise(median_unit_price = median(`Unit Price ($ PSF)`)) %&gt;%\n  mutate(median_unit_price = ifelse(`Property Type` == \"Apartment\", median_unit_price * (-1), median_unit_price)) %&gt;%\n  ungroup()\n\n\n\n\nTransaction Volume Aggregation:\nThe code calculates the maximum and minimum transaction volumes (max_vol, min_vol) for each month and property type, as well as the total transaction volume for each month (sum_transvolume_month).\n\n# transvolume_maxmin as transaction volume by month\ntransvolume_maxmin &lt;- base_data %&gt;%\n  group_by(Month_Sale_Data,`Property Type`) %&gt;%\n  summarise(max_vol = max(abs(Trans_Vol)),\n            min_vol = min(abs(Trans_Vol))) %&gt;%\n  ungroup()\n\n# transvolume_month as total volume by month \ntransvolume_month &lt;- base_data %&gt;%\n  group_by(Month_Sale_Data) %&gt;%\n  summarise(sum_transvolume_month = sum(abs(Trans_Vol))) %&gt;% \n  ungroup()\n\n\n\nTotal Transaction Volume by Property Type:\nIt determines the total transaction volume for each unit price bin and property type combination (sum_transvolume_property).\n\n# transvolume_property as total transaction volume by property type\ntransvolume_property &lt;- base_data %&gt;%\n  group_by(Unit_Price_Bin, `Property Type`) %&gt;%\n  summarise(sum_transvolume_property = sum(Trans_Vol)) %&gt;%\n  ungroup()\n\n\n\nJoining Tables\n\n# joining multiple tables\ntransaction_data &lt;- base_data %&gt;%\n  left_join(transvolume_maxmin, by = c('Month_Sale_Data', 'Property Type')) %&gt;%\n  left_join(transvolume_month, by = 'Month_Sale_Data') %&gt;%\n  left_join(transvolume_property, by = c('Unit_Price_Bin', 'Property Type')) %&gt;%\n  left_join(UnitPrice_median, by = c('Month_Sale_Data', 'Property Type'))\n\ntransaction_data$Unit_Price_Bin &lt;- factor(transaction_data$Unit_Price_Bin, exclude = NULL)\n\n\n\nSignal Creation:\nThe code generates signals (signal, signal1) to indicate whether a transaction volume or median unit price falls within certain ranges, differentiating between property types. These signals are based on conditions comparing transaction volumes and median unit prices with predefined ranges.\n\n\nShow the code\ntransaction_data &lt;- transaction_data %&gt;%\n   mutate(signal = case_when((min_vol == abs(Trans_Vol) | max_vol == abs(Trans_Vol)) & `Property Type` == \"Apartment\" ~ -1,\n                             (min_vol == abs(Trans_Vol) | max_vol == abs(Trans_Vol)) & `Property Type` == \"Condominium\" ~ 1, TRUE~0)) %&gt;%\n\n# Assuming `Unit_Price_Bin` is a factor with ordered levels representing price ranges\n\nmutate(signal1 = case_when(\n    `Property Type` == \"Apartment\" & abs(median_unit_price) &gt;= as.numeric(sub(\"\\\\-(\\\\d+)$\", \"\", Unit_Price_Bin)) & \n    abs(median_unit_price) &lt;= as.numeric(sub(\"^\\\\d+\\\\-\", \"\", Unit_Price_Bin)) ~ -1,\n    \n    `Property Type` == \"Condominium\" & abs(median_unit_price) &gt;= as.numeric(sub(\"\\\\-(\\\\d+)$\", \"\", Unit_Price_Bin)) & \n    abs(median_unit_price) &lt;= as.numeric(sub(\"^\\\\d+\\\\-\", \"\", Unit_Price_Bin)) ~ 1,\n    \n    TRUE ~ 0\n))\n\n\n#Order factors\ntransaction_data$`Property Type` &lt;- fct_relevel(transaction_data$`Property Type`, \"Apartment\")\ntransaction_data$Unit_Price_Bin  &lt;- fct_relevel(transaction_data$Unit_Price_Bin, \"751-1000\", \"1001-1250\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Visual Statistical Analysis with ggstatsplot",
    "text": "Visual Statistical Analysis with ggstatsplot\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nImporting data\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows\n\n\n\n\nOne-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nUnpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nTwo-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nOneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nggbetweenstats - Summary of tests\n\n\n\n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\nSignificant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Visualising Models",
    "text": "Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started-1",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\nMultiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\nModel Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\nVisualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\nVisualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly,patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     #&lt;&lt;\n  \"Name = \", exam_data$ID,         #&lt;&lt;\n  \"\\n Class = \", exam_data$CLASS)) #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #&lt;&lt;\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  opti\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {   #&lt;&lt;\n  mean &lt;- scales::number(y, accuracy = accuracy) #&lt;&lt;\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy) #&lt;&lt;\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #&lt;&lt;\n} #&lt;&lt;\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #&lt;&lt;\n                     tooltip(y, ymax))),  #&lt;&lt;\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #&lt;&lt;\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #&lt;&lt;\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #&lt;&lt;\n    opts_hover(css = \"fill: #202020;\"),  #&lt;&lt;\n    opts_hover_inv(css = \"opacity:0.2;\") #&lt;&lt;\n  )                                      #&lt;&lt;  \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #&lt;&lt;\n        data_id = CLASS),#&lt;&lt;              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #&lt;&lt;\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n:::\nWarning\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #&lt;&lt;\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nThe output:\n\n\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #&lt;&lt;\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #&lt;&lt;\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)  #&lt;&lt;\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\n3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#reference",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\nData import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     #&lt;&lt;\n  \"Name = \", exam_data$ID,         #&lt;&lt;\n  \"\\n Class = \", exam_data$CLASS)) #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #&lt;&lt;\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  opti\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {   #&lt;&lt;\n  mean &lt;- scales::number(y, accuracy = accuracy) #&lt;&lt;\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy) #&lt;&lt;\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #&lt;&lt;\n} #&lt;&lt;\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #&lt;&lt;\n                     tooltip(y, ymax))),  #&lt;&lt;\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #&lt;&lt;\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #&lt;&lt;\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #&lt;&lt;\n    opts_hover(css = \"fill: #202020;\"),  #&lt;&lt;\n    opts_hover_inv(css = \"opacity:0.2;\") #&lt;&lt;\n  )                                      #&lt;&lt;  \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #&lt;&lt;\n        data_id = CLASS),#&lt;&lt;              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #&lt;&lt;\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n:::\nWarning\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #&lt;&lt;\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nThe output:\n\n\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #&lt;&lt;\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #&lt;&lt;\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)  #&lt;&lt;\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\n3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#reference",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries",
    "title": "In-class Exercise 04",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\nData import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nParametric\n\nset.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\",\n  test.value = 60,\n  bin.args =list(color =\"black\",\n                 fill = \"grey50\",\n                 alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth =2),\n  xlab = \"English scores\"\n)\n\np\n\n\n\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 15\n     mu statistic df.error  p.value method            alternative effectsize\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n1    60      8.77      321 1.04e-16 One Sample t-test two.sided   Hedges' g \n  estimate conf.level conf.low conf.high conf.method conf.distribution n.obs\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;int&gt;\n1    0.488       0.95    0.372     0.603 ncp         t                   322\n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.54      8.75     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\n\nBayes\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  bin.args =list(color =\"black\",\n                 fill = \"grey50\",\n                 alpha = 0.7),\n  normal.curve = TRUE,\n  normal.curve.args = list(linewidth =2),\n  xlab = \"English scores\"\n)\n\n\n\n\n\nggdotplotstats(\n  data = exam,\n  x= ENGLISH,\n  y= CLASS,\n  title = \"\",\n  xlab = \"\"\n)\n\n\n\n\n\n#### data preparation step for visualization using pivot_longer\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n  filter(CLASS == \"3A\")\n  \n\n#### visualization after pivoting\nggwithinstats(\n  data    = filter(exam_long,\n                   SUBJECT %in%\n                     c(\"MATHS\", \"SCIENCE\")),\n  x= SUBJECT,\n  y= SCORES,\n  type = \"p\"\n)\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#funnel-plots",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#funnel-plots",
    "title": "In-class Exercise 04",
    "section": "Funnel Plots",
    "text": "Funnel Plots\nNext, we explore Funnel Plots"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates",
    "text": "Visualizing the uncertainty of point estimates\nA point estimate is a single number, such as a mean. Uncertainty is expressed as standard error, confidence interval, or credible interval\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics. my_sum.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\nPlotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean +/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\nPlotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race..\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\nVisualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #&lt;&lt;\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\nwidth = 0.95\npoint = median\ninterval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\n\n\n\n\n\nYour turn\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "FunnelPlotR methods",
    "text": "FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "title": "Hands-on Exercise 4c: Building Funnel Plot with R",
    "section": "References",
    "text": "References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.2 Getting Started",
    "text": "29.2 Getting Started\n\n29.2.1 Installing and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nThe code chunk:\n\npacman::p_load(tidytext ,widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms, tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.3 Importing Multiple Text Files from Multiple Folders",
    "text": "29.3 Importing Multiple Text Files from Multiple Folders\n\n29.3.1 Creating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\n\n29.3.2 Define a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.4 Importing Multiple Text Files from Multiple Folders",
    "text": "29.4 Importing Multiple Text Files from Multiple Folders\n\n29.4.1 Reading in all the messages from the 20news folder\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above:\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.5 Initial EDA",
    "text": "29.5 Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\n\n\n\n\nThe code chunk:\n\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarise(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages,newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y=NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.6 Introducing tidytext",
    "text": "29.6 Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n29.6.1 Removing header and automated email signitures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup , id) %&gt;%\n  filter(cumsum(text ==\"\") &gt;0,\n         cumsum(str_detect(\n           text, \"^--\")) ==0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk:\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n29.6.2 Removing lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk:\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n29.6.3 Text Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n29.6.4 Visualising Words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\nDT::datatable(words_by_newsgroup , class= \"newsgroup\")\n\n\n\n\n\n\n\n\n29.6.5 Visualising Words in newsgroups\nThe wordcloud below is plotted by using ggwordcloud package.\n\n\n\n\n\nThe code chunk used:\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.7 Basic Concept of TF-IDF",
    "text": "29.7 Basic Concept of TF-IDF\n\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n29.7.1 Computing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\n29.7.2 Visualising tf-idf as interactive table\nTable below is an interactive table created by using datatable().\n\n\n\n\n\n\n\n\n\n29.7.3 Visualising tf-idf as interactive table\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk:\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link.\n\n\n29.7.4 Visualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\n\n\n\n\nThe code chunk used to prepare the plot.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n29.7.5 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\n29.7.6 Visualising correlation as a network\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\n\n\n\n\nThe code chunk:\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n29.7.7 Bigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\nbigrams\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows\n\n\n\n\n29.7.8 Counting bigrams\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows\n\n\n\n\n29.7.9 Cleaning bigram\nThe code chunk below is used to seperate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\nbigrams_filtered\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows\n\n\n\n\n29.7.10 Counting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\n29.7.11 Create a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH bd3ac3a DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from bd3ac3a (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n29.7.12 Visualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\n\n\n\n\nThe code chunk used to plot the network graph:\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n29.7.13 Revised version\n\n\n\n\n\nThe code chunk used to plot the network graph:\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "29.8 References",
    "text": "29.8 References\n\n29.8.0.1 widyr\n\nReference guide\n\nwidyr: Widen, process, and re-tidy a dataset\nUnited Nations Voting Correlations"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-required-libraries",
    "title": "In-class Exercise 05",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(readtext, quanteda, tidytext,  tidyverse)\n\n\nData import and preparation (Text)\nFor the purpose of this exercise, data from MC1 of Vast CGallenge 2024 will be used.\n\ntext_data &lt;- readtext(paste0(\"data/articles\", \"/*\"))\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word,text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\",\"Y\"),\n                       too_few = \"align_end\")\n\n\n\nData import and preparation (JSON)\n\npacman::p_load(jsonlite , tidyverse)\n\n\nmc1_data &lt;- fromJSON(\"data/mc1.json\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "The Data",
    "text": "The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nThe edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data-1",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "The Data",
    "text": "The Data\n\nThe nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-network-data-from-files",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-network-data-from-files",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Importing network data from files",
    "text": "Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\nReviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nNote\n\n\n\nWarning: The output report of GAStech_edges above reveals that the SentDate is treated as “Character”” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\nWrangling time\nThe code chunk below will be used to perform the changes.\n\n\nShow the code\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\nReviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\n\nShow the code\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\n\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\nReviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 – A tidy hope\n\n\nThe tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "The dplyr verbs in tidygraph",
    "text": "The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\nUsing tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\n\nShow the code\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\nReviewing the output tidygraph’s graph object\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\nReviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-network-data-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-network-data-with-ggraph-package",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Plotting Network Data with ggraph package",
    "text": "Plotting Network Data with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\n[edges]((https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html) and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\nChanging the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\n\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\nChanging the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nWorking with ggraph’s layouts\nggraph() support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\nFruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\nModifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\nModifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nWorking with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nA framed facet graph\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nWorking with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\nVisualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\nData preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nShow the code\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nPlotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nShow the code\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\nWorking with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nShow the code\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument. ]\n\n\nInteractivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "See link below for additional details on this challenge!\nhttps://vast-challenge.github.io/2024/index.html"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#installing-and-loading-the-required-libraries",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#installing-and-loading-the-required-libraries",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "",
    "text": "Show the code\npacman::p_load(readtext, quanteda, tidytext,  tidyverse)\n\n\n\n\nShow the code\ntext_data &lt;- readtext(paste0(\"data/articles\", \"/*\"))\n\n\n\n\nShow the code\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word,text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\n\n\n\n\n\nShow the code\npacman::p_load(jsonlite, igraph, textdata, tm)\n\n\n\n\nShow the code\nmc1_data &lt;- fromJSON(\"data/mc1.json\")\n\n\n\n\nShow the code\nmc1_links &lt;- as_tibble(mc1_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n# Convert nodes to tibble, modify variable types, and select required columns\nmc1_nodes &lt;- as_tibble(mc1_data$nodes) %&gt;%\n  mutate(id = as.character(id), \n         type = as.character(type), \n         country = as.character(country)) %&gt;%\n  select(id, country, type )\n\n\n\n\n\n\n\n\n# shadgpt_nodes &lt;- mc1_links$links %&gt;%\n#   filter(_algorithm == \"ShadGPT\")\n\n\n# bassline_nodes &lt;- mc1_links$links \n# filter(_algorithm == \"BassLine\")\n\n\n# Extract articles related to these nodes and edges\n# shadgpt_articles &lt;- usenet_words[shadgpt_nodes$_raw_source]\n# bassline_articles &lt;- usenet_words[bassline_nodes$_raw_source]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-r-packages",
    "title": "Take Home Exercise 3",
    "section": "1.1 Loading R Packages",
    "text": "1.1 Loading R Packages\nIn the code chunk, p_load() and pacman package is used to load the required packages below:\n\ntidyverse\n\nPurpose: A collection of R packages designed for data science, including ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, and forcats. These packages share an underlying design philosophy, grammar, and data structures.\n\nsf\n\nPurpose: Simple Features for R, which provides support for handling spatial vector data. It enables manipulation and analysis of spatial data within the tidyverse framework.\n\nlwgeom\n\nPurpose: Provides additional functionality for sf objects, leveraging the liblwgeom library. This is used for advanced spatial operations like validating geometries.\n\ntmap\n\nPurpose: Thematic maps, which allows for flexible and powerful creation of thematic maps with an intuitive syntax.\n\nunits\n\nPurpose: Support for measurement units in R. This package allows for easy and explicit management of physical measurement units in data frames.\n\nmaps\n\nPurpose: Provides map data for the creation of maps in R. Useful for adding geographical context to visualizations.\n\nigraph\n\nPurpose: A package for creating and manipulating graphs. It provides tools for network analysis and visualization.\n\ntidygraph\n\nPurpose: Integrates tidy data principles into graph data structures. It allows for the manipulation of graph data using dplyr verbs.\n\nggraph\n\nPurpose: An extension of ggplot2 for graph visualization. It is used for creating network graphs using the ggplot2 grammar.\n\nvisNetwork\n\nPurpose: Interactive network visualization using the vis.js library. It allows for the creation of interactive network graphs.\n\nlubridate\n\nPurpose: Simplifies the process of working with dates and times in R. It provides functions for parsing, manipulating, and doing arithmetic with date-time objects.\n\njsonlite\n\nPurpose: A robust, high-performance JSON parser and generator for R. It is used for converting between JSON data and R objects.\n\nhttr\n\nPurpose: A package for working with URLs and HTTP. It provides tools for making HTTP requests and interacting with web APIs.\n\nviridis\n\nPurpose: Color maps designed to be perceptually uniform. It provides color scales that are particularly useful for heatmaps and other data visualizations.\n\nplotly\n\nPurpose: Interactive web-based plots. It is used to create interactive plots that can be embedded in web pages or viewed in RStudio.\n\nggrepel\n\nPurpose: Provides geoms for ggplot2 to repel overlapping text labels. This helps in creating more readable plots by preventing text labels from overlapping.\n\n\n\n\nShow the code\npacman::p_load(tidyverse, sf, lwgeom, tmap, units, maps, igraph, tidygraph, ggraph, visNetwork, lubridate, jsonlite, httr,tmap,viridis,plotly, ggrepel)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-the-data",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-the-data",
    "title": "Take Home Exercise 3",
    "section": "1.2. Loading the Data",
    "text": "1.2. Loading the Data\n\nLinksNodes\n\n\nIn this section, we will prepare our links dataset\nIn this section, we use thejsonlite package to read our data in a JSON (JavaScript Object Notation) file named mc2_edited.json and convert it into an R object for further analysis and manipulation.\n\n\nShow the code\nmc2_data &lt;- fromJSON(\"data/mc2_edited.json\")\n\n\nWe first convert the links data from the JSON object into a tibble using dplyr and perform following transformations:\n\nRemoving Duplicates: The distinct() function is used to ensure that only unique rows are retained in the dataset, removing any duplicate records.\nData Type Conversion:\n\nsource, target, type, dwell, and raw_source are converted to character strings using as.character().\ntime is converted to a POSIXct date-time object with the format %Y-%m-%dT%H:%M:%OS and time zone UTC to ensure proper handling of time data.\ndate is converted to a Date object with the format %Y-%m-%d.\nping_date is derived from the time column, also converted to a Date object after transforming it to POSIXct format.\n\nColumn Selection: The select() function is used to keep only the relevant columns for further analysis, specifically type, time, dwell, source, target, date, ping_date, and raw_source.\nAggregation and Filtering:\n\nGrouping: The data is grouped by source, target, and type to prepare for aggregation.\nSummarizing: The summarise() function calculates the number of interactions (weights) between each pair of source and target for each type.\nFiltering: The filter() function removes any rows where the source is the same as the target, eliminating self-loops in the network.\nUngrouping: Finally, the ungroup() function ensures that the resulting dataset is no longer grouped, making it easier to work with in subsequent steps.\n\n\n\n\nShow the code\nmc2_links_prep &lt;- as_tibble(mc2_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type),\n         dwell = as.character(dwell),\n         raw_source = as.character(raw_source),\n         time =  as.POSIXct(time, format=\"%Y-%m-%dT%H:%M:%OS\", tz=\"UTC\"),\n         date = as.Date(as.character(date), format = \"%Y-%m-%d\"),\n         ping_date = as.Date(as.POSIXct(time, format=\"%Y-%m-%dT%H:%M:%OS\", tz=\"UTC\"))) %&gt;%\n  select(type, time, dwell, source, target, date, ping_date)\n\n\nmc2_links &lt;- mc2_links_prep%&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n(), .groups = 'drop') %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\n\n\nIn this section, we will prepare our nodes dataset\nSimilarly, we extract the nodes data from the JSON object into a tibble and perform the following transformations to the data:\n\nType Original: A new column type_original is created to store the original values of the type column.\nData Type Conversion: Several columns are converted to appropriate data types:\n\nid and type are converted to character strings.\ntonnage and length_overall are converted to numeric values after ensuring they are in character format.\nActivities, fish_species_present, kind, flag_country, company, raw_source, and name are converted to character strings.\nlast_edited_by, last_edited_date, and date_added are converted to POSIXct date-time objects using the strptime function to parse the dates correctly.\n\nType Classification: The type column is recategorized to a more general “Entity.Vessel” if the original type falls into specific vessel categories such as “Entity.Vessel.CargoVessel,” “Entity.Vessel.Ferry.Cargo,” “Entity.Vessel.FishingVessel,” or “Entity.Vessel.Other.” If the type does not match these categories, it remains unchanged.\nColumn Selection: The final step is selecting relevant columns for further analysis. The selected columns include id, type, type_original, namee, company, flag_country, Activities, tonnage, length_overall, raw_source, fish_species_present, and kind.\n\n\n# Convert nodes to tibble, modify variable types, and select required columns\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  mutate(\n    type_original = type,\n    id = as.character(id), \n    type = as.character(type),\n    type = case_when(\n      type %in% c(\"Entity.Vessel.CargoVessel\", \"Entity.Vessel.Ferry.Cargo\", \"Entity.Vessel.FishingVessel\", \"Entity.Vessel\", \"Entity.Vessel.Other\") ~ \"Entity.Vessel\",\n      TRUE ~ type\n    ),\n    tonnage = as.numeric(as.character(tonnage)),\n    length_overall = as.numeric(as.character(length_overall)), \n    Activities = as.character(Activities), \n    fish_species_present = as.character(fish_species_present), \n    kind = as.character(kind), \n    flag_country = as.character(flag_country),\n    company = as.character(company),\n    raw_source = as.character(raw_source),\n    namee = as.character(name), \n    last_edited_by = as.POSIXct(strptime(as.character(last_edited_by), format = \"%Y-%m-%dT%H:%M:%OS\")),\n    last_edited_date = as.POSIXct(strptime(as.character(last_edited_date), format = \"%Y-%m-%dT%H:%M:%OS\")),\n    date_added = as.POSIXct(strptime(as.character(date_added), format = \"%Y-%m-%dT%H:%M:%OS\"))\n  ) %&gt;%\n  select(id, type,type_original, namee, company, flag_country, Activities, tonnage, length_overall, fish_species_present, kind)\n\n\n\n\n\n\n\nNote\n\n\n\nWe save our processed data into .rds data format files using the write_rds() of readr package. The output file is saved in rds sub-folder. We do this to reduce the loading time and more importantly, we can avoid uploading the large raw files onto GitHub.\n\n\n\nwrite_rds(mc2_links_prep, \"data/rds/mc2_links_prep.rds\")\nmc2_links_prep &lt;- read_rds(\"data/rds/mc2_links_prep.rds\")\n\nwrite_rds(mc2_links, \"data/rds/mc2_links.rds\")\nmc2_links &lt;- read_rds(\"data/rds/mc2_links.rds\")\n\nwrite_rds(mc2_nodes, \"data/rds/mc2_nodes.rds\")\nmc2_nodes &lt;- read_rds(\"data/rds/mc2_nodes.rds\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-cleaning",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-cleaning",
    "title": "Take Home Exercise 3",
    "section": "1.3. Data Cleaning",
    "text": "1.3. Data Cleaning\n\nLinksNodesGeographical Information\n\n\nWe discovered that the columns “type,” “source,” and “target” are complete, containing no missing values. Conversely, the columns “time,” “dwell,” “date,” and “ping_date” exhibit numerous missing values. This outcome is anticipated since these columns exclusively hold data for specific categories.\n\n# Check for columns with missing values\ncolSums(is.na(mc2_links_prep))\n\n     type      time     dwell    source    target      date ping_date \n        0     13101     13101         0         0    258542     13101 \n\n\n\n\nShow the code\nsummary(mc2_links_prep)\n\n\n     type                time                           dwell          \n Length:271643      Min.   :2035-02-01 00:00:00.00   Length:271643     \n Class :character   1st Qu.:2035-04-17 13:33:02.35   Class :character  \n Mode  :character   Median :2035-06-28 19:34:55.25   Mode  :character  \n                    Mean   :2035-06-30 22:13:03.65                     \n                    3rd Qu.:2035-09-13 13:44:34.00                     \n                    Max.   :2035-11-30 00:00:00.00                     \n                    NA's   :13101                                      \n    source             target               date           \n Length:271643      Length:271643      Min.   :2035-02-01  \n Class :character   Class :character   1st Qu.:2035-07-25  \n Mode  :character   Mode  :character   Median :2035-09-19  \n                                       Mean   :2035-08-29  \n                                       3rd Qu.:2035-10-26  \n                                       Max.   :2035-11-30  \n                                       NA's   :258542      \n   ping_date         \n Min.   :2035-02-01  \n 1st Qu.:2035-04-17  \n Median :2035-06-28  \n Mean   :2035-06-30  \n 3rd Qu.:2035-09-13  \n Max.   :2035-11-30  \n NA's   :13101       \n\n\nNext, we ensure there are no duplicated rows\n\n\nShow the code\nmc2_links[duplicated(mc2_links),]\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: source &lt;chr&gt;, target &lt;chr&gt;, type &lt;chr&gt;, weights &lt;int&gt;\n\n\nLet’s try to understand how our links data is categorized into. It seems there are three categories of data as shown below.\n\n\nShow the code\nunique_type &lt;- unique(mc2_links$type)\nprint(unique_type)\n\n\nDefine a function to count and print unique categories for a given column.\n\n\nShow the code\ncount_unique_categories &lt;- function(data, column_name) {\n  cat(\"**\", column_name, \"**\\n\", sep = \"\")\n  category_counts &lt;- table(data[[column_name]])\n  sorted_counts &lt;- sort(category_counts, decreasing = TRUE)\n  print(sorted_counts)\n}\n\n\n\n\nLet’s take a look into our nodes dataframe.\n\n\nShow the code\nglimpse(mc2_nodes)\n\n\nRows: 5,637\nColumns: 11\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ type_original        &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ namee                &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n$ tonnage              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n\n\nAgain, it’s hard to make sense if these missing values are actually important due ot the nature of the data. We shall handle it as it goes. However, the main columns we are interested in id and type are not missing any data.\n\n\nShow the code\n# Check for columns with missing values\ncolSums(is.na(mc2_nodes))\n\n\n                  id                 type        type_original \n                   0                    0                    0 \n               namee              company         flag_country \n                5627                 5458                 5341 \n          Activities              tonnage       length_overall \n                   0                 5359                 5354 \nfish_species_present                 kind \n                   0                 5613 \n\n\nThere does not seem to be any whole duplicate rows.\n\n\nShow the code\nmc2_nodes[duplicated(mc2_nodes),]\n\n\n# A tibble: 0 × 11\n# ℹ 11 variables: id &lt;chr&gt;, type &lt;chr&gt;, type_original &lt;chr&gt;, namee &lt;chr&gt;,\n#   company &lt;chr&gt;, flag_country &lt;chr&gt;, Activities &lt;chr&gt;, tonnage &lt;dbl&gt;,\n#   length_overall &lt;dbl&gt;, fish_species_present &lt;chr&gt;, kind &lt;chr&gt;\n\n\nIt seems we have many types of nodes even after grouping more of the Vessel types into our generic “Entity.Vessel”. It seems “Entity.Commodity.Fish”,‘Entity.Vessel’, ‘Entity.Location.Point’, ‘Entity.Location.City’, ‘Entity.Location.Region’ will be important for us.\n\n\nShow the code\nunique_type &lt;- unique(mc2_nodes$type)\nprint(unique_type)\n\n\n\n\nShow the code\ncount_unique_categories(mc2_nodes, 'type') \ncount_unique_categories(mc2_nodes, 'flag_country') \ncount_unique_categories(mc2_nodes, 'kind') \n\n\nThere are 100 companies found in our dataset\n\ncount_unique_companies &lt;- length(unique(mc2_nodes$company))\ncount_unique_companies\n\n[1] 100\n\n\n\n\nThe code below snippet employs the sf package to read and manipulate GeoJSON data. It uses st_read() to import the GeoJSON file and renames the column “Name” to “id” using rename() from the dplyr package.\n\n\nShow the code\n# Read the GeoJSON file\ngeojson_file &lt;- \"data/Oceanus Information/Oceanus Geography.geojson\"\ngeo_data &lt;- st_read(geojson_file) %&gt;%\n  rename(id = Name)\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\weipengten\\ISSS608\\ISSS608-VAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\Oceanus Information\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\nUsing tmap we create a basic plot of our locations we are interested in.\n\n\nShow the code\n# Visualize the geographical data with tmap\ntmap_mode(\"plot\")\n\ntm_shape(geo_data) +\n  tm_polygons(alpha = 0.5) +\n  tm_borders(lwd = 1, alpha = 0.5) +\n  tm_layout(frame = FALSE) +\n  tmap_style(\"gray\") +\n  tm_shape(geo_data) +\n  tm_dots(col = \"purple\", size = 0.2) +\n  tm_text(text = \"id\", size = 0.6, col = \"black\") +  # Add labels to the locations\n  tm_layout(legend.position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries",
    "title": "In-class Exercise 06",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(stringi, rvest, corporaexplorer, tidytext,  tidyverse, quanteda)\n\n\nData import and preparation (Text)\n\n#bible &lt;- readr::read_lines(\"http://www.gotenberg.org/cache/epub/10/pg10.txt\")\nbible &lt;- readr::read_lines(\"data/bible.txt\")\n\n\n\nPre-processing the text\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\",\n                         \"NEW_PARAGRAPH\") %&gt;%\n  str_replace_all(\"\\n\", \" \") %&gt;%\n  str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\",\n                            \"NEW_CHAPTER\\\\1\") %&gt;%\n  stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n#Metadata\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n#Creating data frame with text and metadata\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n\ncorporaexplorer\n\n#When we first have a data frame with text and metadata, creating a “corporaexplorerobject” for exploration is very simple:\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\n#Run corpus explorer\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#installing-and-loading-the-required-libraries",
    "title": "In-class Exercise 06a: Text Visualisations",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(stringi, rvest, corporaexplorer, tidytext,  tidyverse, quanteda)\n\n\nData import and preparation (Text)\n\n#bible &lt;- readr::read_lines(\"http://www.gotenberg.org/cache/epub/10/pg10.txt\")\nbible &lt;- readr::read_lines(\"data/bible.txt\")\n\n\n\nPre-processing the text\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\",\n                         \"NEW_PARAGRAPH\") %&gt;%\n  str_replace_all(\"\\n\", \" \") %&gt;%\n  str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\",\n                            \"NEW_CHAPTER\\\\1\") %&gt;%\n  stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n#Metadata\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n#Creating data frame with text and metadata\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n\ncorporaexplorer\n\n#When we first have a data frame with text and metadata, creating a “corporaexplorerobject” for exploration is very simple:\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\n#Run corpus explorer\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#installing-and-loading-the-required-libraries",
    "title": "In-class Exercise 06b: Network Visualisation",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, ggforce, skimr, tidytext, jsonlite)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-the-data",
    "title": "In-class Exercise 06b: Network Visualisation",
    "section": "Loading the Data",
    "text": "Loading the Data\n\nmc3_data &lt;- fromJSON(\"data/MC3_2023.json\")\n\n\nLinksNodes\n\n\n\n\nShow the code\nmc3_edges &lt;-\n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target = \n           as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights=n()) %&gt;%\n  filter(source!= target) %&gt;%\n  ungroup()\n\n\n\n\n\n\nShow the code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(id = as.character(id), \n         type = as.character(type), \n         country = as.character(country), \n         product_services = as.character(product_services),\n  # Convert to character first to unlist, then revert to numeric form \n         revenue_omu = as.numeric(as.character(revenue_omu))) %&gt;%\n  # Reorganize columns \n  select(id, country, type, revenue_omu, product_services)\n\n\n\n\n\n\n\nShow the code\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n\nmc3_nodes1 &lt;- bind_rows(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes, by = \"id\", unmatched = \"drop\")\n\n\n\n\nShow the code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\n\n\nShow the code\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 300000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha=0.5)) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph()\n\n\n\n\n\n\n\nShow the code\nmc3_graph_directed &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = TRUE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-1",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-1",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "2. Task 1",
    "text": "2. Task 1\n\n2.1` Filter and Prepare Data\n\n\nShow the code\n# Filter and prepare nodes\nmc2_nodes_filtered &lt;- mc2_nodes %&gt;%\n  filter(type %in% c('Entity.Vessel','Entity.Location.Point',\"Entity.Location.City\")) \n\n# Filter and prepare nodes\nmc2_links_filtered &lt;- mc2_links %&gt;%\n  filter(type %in% c('Event.TransportEvent.TransponderPing','Event.Transaction',\"Event.HarborReport\"))\n\n# Extract relevant node IDs\nfiltered_node_ids &lt;- mc2_nodes_filtered$id\n\n# Filter and prepare edges\nmc2_links_filtered &lt;- mc2_links_filtered %&gt;%\n  filter(source %in% filtered_node_ids & target %in% filtered_node_ids)\n\n# Ensure no missing nodes in the filtered links\nmissing_nodes &lt;- setdiff(unique(c(mc2_links_filtered$source, mc2_links_filtered$target)), mc2_nodes_filtered$id)\nif(length(missing_nodes) &gt; 0) {\n  mc2_links_filtered &lt;- mc2_links_filtered %&gt;%\n    filter(!source %in% missing_nodes & !target %in% missing_nodes)\n}\n\n\n\n\n2.2. Construct the Graph\n\n\nShow the code\n# Create the graph with filtered nodes and edges\nmc2_graph &lt;- tbl_graph(nodes = mc2_nodes_filtered, edges = mc2_links_filtered, directed = TRUE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness(),\n         degree_centrality = centrality_degree())\n\n\n\n\n2.3. Filter out Isolated Edges\n\n\nShow the code\n# Filter the graph to include only nodes with edges\nmc2_graph_with_edges &lt;- mc2_graph %&gt;%\n  filter(!node_is_isolated())\n\n# Visualization with filtered nodes\nmc2_graph_with_edges %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5), show.legend = FALSE) +\n  geom_node_point(aes(\n    size = degree_centrality,\n    color = type,\n    alpha = 0.3)) +\n  scale_size_continuous(range = c(1, 10)) +\n  scale_color_manual(values = c(\"Entity.Vessel\" = \"blue\", \n                                \"Entity.Location.Point\"= \"red\",\n                                \"Entity.Location.City\" = \"lightblue\"\n                                )) +\n  labs(title = \"Associations between Vessels and Probable Cargos\",\n       color = \"Node Type\",\n       size = \"Degree Centrality\")\n\n\n\n\n\n\n\n2.4. Visualize the Graph\n\n\nShow the code\n# Aggregate edges data\nmc2_edges_aggregated &lt;- mc2_links_filtered %&gt;%\n  left_join(mc2_nodes_filtered, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = source) %&gt;%\n  left_join(mc2_nodes_filtered, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = target) %&gt;%\n  group_by(from, to) %&gt;%\n  summarise(weight = sum(weights)) %&gt;%\n  filter(from != to) %&gt;%\n  filter(weight &gt; 50) %&gt;%\n  ungroup()\n\nconnected_nodes &lt;- unique(c(mc2_edges_aggregated$from, mc2_edges_aggregated$to))\n\n# Filter out isolated nodes\nmc2_nodes_filtered &lt;- mc2_nodes_filtered %&gt;%\n  filter(id %in% connected_nodes) %&gt;%\n  rename(group = type) %&gt;%\n  mutate(label = ifelse(group %in% c('Entity.Vessel','Entity.Location.Point', 'Entity.Location.City'), id, NA))\n\n\n\n\nShow the code\n# Visualize the resulting graph\nvisNetwork(mc2_nodes_filtered, mc2_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1), \n             nodesIdSelection = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#geographical-information",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#geographical-information",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "3. Geographical Information",
    "text": "3. Geographical Information\n\n\nShow the code\n# Read the GeoJSON file\ngeojson_file &lt;- \"data/Oceanus Information/Oceanus Geography.geojson\"\ngeo_data &lt;- st_read(geojson_file) %&gt;%\n  st_transform(crs = 3571)%&gt;%\n  rename(id = Name)\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\weipengten\\ISSS608\\ISSS608-VAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\Oceanus Information\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\n\n# Separate MULTIPOLYGON and POINT geometries\nmultipolygon_data &lt;- geo_data %&gt;% filter(st_geometry_type(geo_data) == \"MULTIPOLYGON\")\npoint_data &lt;- geo_data %&gt;% filter(st_geometry_type(geo_data) == \"POINT\")\n\n\n\nShow the code\n# Merge geographical information into network nodes\nmc2_nodes_geo &lt;- mc2_nodes_filtered %&gt;%\n  left_join(st_drop_geometry(geo_data), by = \"id\")\n\n\n\n\nShow the code\n# Visualize the geographical data with tmap\ntmap_mode(\"plot\")\n\ntm_shape(geo_data) +\n  tm_polygons(alpha = 0.5) +\n  tm_borders(lwd = 1, alpha = 0.5) +\n  tm_layout(frame = FALSE) +\n  tmap_style(\"gray\") +\n  tm_shape(geo_data) +\n  tm_dots(col = \"purple\", size = 0.2) +\n  tm_text(text = \"id\", size = 0.6, col = \"black\") +  # Add labels to the locations\n  tm_layout(legend.position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-eda",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-eda",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "2. Task 2 : EDA",
    "text": "2. Task 2 : EDA\n\n2.1` Filter and Prepare Data2.2. Construct the Graph2.3. Filter out Isolated Edges\n\n\n\n\nShow the code\n# Filter and prepare nodes\nmc2_nodes_suspect &lt;- mc2_nodes %&gt;%\n  filter(type %in% c('Entity.Vessel', 'Entity.Location.Point', 'Entity.Location.City', 'Entity.Location.Region')) %&gt;%\n  filter(!(type == 'Entity.Vessel' & company != \"SouthSeafood Express Corp\"))\n\n# Filter and prepare nodes\nmc2_links_filtered &lt;- mc2_links %&gt;%\n  filter(type %in% c('Event.TransportEvent.TransponderPing','Event.Transaction',\"Event.HarborReport\"))\n\n# Extract relevant node IDs\nfiltered_node_ids &lt;- mc2_nodes_suspect$id\n\n# Filter and prepare edges\nmc2_links_suspect &lt;- mc2_links_filtered %&gt;%\n  filter(source %in% filtered_node_ids & target %in% filtered_node_ids)\n\n# Ensure no missing nodes in the filtered links\nmissing_nodes &lt;- setdiff(unique(c(mc2_links_suspect$source, mc2_links_suspect$target)), mc2_nodes_suspect$id)\nif(length(missing_nodes) &gt; 0) {\n  mc2_links_suspect &lt;- mc2_links_suspect %&gt;%\n    filter(!source %in% missing_nodes & !target %in% missing_nodes)\n}\n\n\n\n\n\n\nShow the code\n# Create the graph with filtered nodes and edges\nmc2_graph &lt;- tbl_graph(nodes = mc2_nodes_suspect, edges = mc2_links_suspect, directed = TRUE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness(),\n         degree_centrality = centrality_degree())\n\n\n\n\n\n\nShow the code\n# Filter the graph to include only nodes with edges\nmc2_graph_with_edges &lt;- mc2_graph %&gt;%\n  filter(!node_is_isolated())\n\n# Visualization with filtered nodes\nmc2_graph_with_edges %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5), show.legend = FALSE) +\n  geom_node_point(aes(\n    size = degree_centrality,\n    color = type,\n    alpha = 0.3)) +\n  geom_node_text(aes(label = id), repel = TRUE, size = 3, vjust = 1.5) +  # Add labels to nodes\n  scale_size_continuous(range = c(1, 10)) +\n  scale_color_manual(values = c(\"Entity.Vessel\" = \"blue\", \n                                \"Entity.Location.Point\"= \"red\",\n                                \"Entity.Location.Region\" =\"green\",\n                                \"Entity.Location.City\" = \"lightblue\"\n                                )) +\n  labs(title = \"SouthSeafood Express Corp's Activities\",\n       color = \"Node Type\",\n       size = \"Degree Centrality\")\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Aggregate edges data\nmc2_links_suspect &lt;- mc2_links_suspect %&gt;%\n  left_join(mc2_nodes_suspect, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = source) %&gt;%\n  left_join(mc2_nodes_suspect, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = target) %&gt;%\n  group_by(from, to) %&gt;%\n  summarise(weight = sum(weights)) %&gt;%\n  filter(from != to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\nconnected_nodes &lt;- unique(c(mc2_links_suspect$from, mc2_links_suspect$to))\n\n# Filter out isolated nodes\nmc2_nodes_suspect &lt;- mc2_nodes_suspect %&gt;%\n  filter(id %in% connected_nodes) %&gt;%\n  rename(group = type) %&gt;%\n  mutate(label = ifelse(group %in% c('Entity.Vessel', 'Entity.Location.Point', 'Entity.Location.City',\"Entity.Location.Region\"), id, NA)) %&gt;%\n  group_by(company) %&gt;%\n  mutate(id1 = if_else(group == \"Entity.Vessel\" & company != \"\" & !is.na(company),\n                       paste0(company, row_number()),\n                       if_else(group == \"Entity.Vessel\" & (company == \"\" | is.na(company)), id, NA_character_)),\n         id1 = if_else(group != \"Entity.Vessel\", id, id1)) %&gt;%\n  ungroup()\n\n\n### Visualize the Graph\n\n# Visualize the resulting graph\nvisNetwork(mc2_nodes_suspect, mc2_links_suspect) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1),\n             nodesIdSelection = TRUE,\n             selectedBy = \"type\")  # Add type dropdown"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-deep-investigations-into-southseafood-express-corp",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-deep-investigations-into-southseafood-express-corp",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "2. Task 2 : Deep Investigations into \"SouthSeafood Express Corp\"",
    "text": "2. Task 2 : Deep Investigations into \"SouthSeafood Express Corp\"\nThe date \"SouthSeafood Express Corp\"was caught is likely to be just after “2035-05-09” which happened to be it’s last harbor report.\n\n\nShow the code\ncommodityfish &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Commodity.Fish\")\n\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\ndate_caught &lt;- max(harboureport_culprit$harboreporting_date)\nprint(date_caught)\n\n\n[1] \"2035-05-09\"\n\n\n\nDeep Investigation into snappersnatcher7bNow Let’s investigate specificly for snappersnatcher7bDeep Investigation into \"roachrobberdb6\"\n\n\nNow let’s derive a function to retrieve the unique fishes found in the regions\n\n\nShow the code\n# Getting the Fish species in Regions the transformation of Fish_Species\nfishspecies_expanded &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Location.Region\") %&gt;%\n  mutate(Fish_Species = str_remove_all(fish_species_present, 'c\\\\(|\\\\)|\"')) %&gt;%\n  mutate(Fish_Species = str_split(Fish_Species, \",\\\\s*\")) %&gt;%\n  unnest(Fish_Species) %&gt;%\n  mutate(Fish_Species = str_trim(Fish_Species)) %&gt;%\n  rename(Region = id)\n\n# Joining the dataframes\nfishspecies_expanded &lt;- fishspecies_expanded %&gt;%\n  left_join(commodityfish, by = c(\"Fish_Species\" = \"namee\")) %&gt;%\n  select(Region, Fish_Species, id)\n\n# Define the function to get commodity fish IDs for specific regions\nget_commodity_fish_ids &lt;- function(..., regions = NULL) {\n  fishspecies_expanded %&gt;%\n    filter(Region %in% c(..., regions)) %&gt;%\n    pull(id)\n}\n\n# Call the function with multiple region names\ncommodity_fish_ids &lt;- unique(get_commodity_fish_ids(\"Ghoti Preserve\", \"Don Limpet Preserve\"))\nprint(commodity_fish_ids)\n\n\n[1] \"labridaenrefert9be\" \"habeaspisces4eb\"    \"piscessatisb87\"    \n[4] \"piscisosseusb6d\"    \"thunnininveradb7\"   \"piscesfrigus900\"   \n[7] \"piscesfoetidaae7\"  \n\n\n\n\nFrom the EDA/ visualisation earlier, it seems “snappersnatcher7be” frequents - Locations: \"Nav1\", \"Nav2\" which is extremely near \"Ghoti Preserve\" and - Region: \"Wrasse Beds\" , \"Ghoti Preserve\", \"Cod Table\" - City: City of Paackland and City of Lomark\nIn \"Ghoti Preserve\", these are the fish species that commonly found. The names are as below:\n\n\nShow the code\n# Pull out the names of the fish species found in Ghoti Preserve\nunique_fish_species_ghoti &lt;- fishspecies_expanded %&gt;%\n  filter(Region == \"Ghoti Preserve\") %&gt;%\n  pull(Fish_Species) %&gt;%\n  unique()\n\n# Print the unique Fish_Species\nprint(unique_fish_species_ghoti)\n\n\n[1] \"Wrasse/Labridae n.refert\" \"Beauvoir/Habeas pisces\"  \n[3] \"Helenaa/Pisces satis\"     \"Offidiaa/Piscis osseus\"  \n\n\nThe ids are:\n\n# Call the function to get id of the fishes for Ghoti Preserve\ncommodity_fish_ids &lt;- get_commodity_fish_ids(\"Ghoti Preserve\")\nprint(commodity_fish_ids)\n\n[1] \"labridaenrefert9be\" \"habeaspisces4eb\"    \"piscessatisb87\"    \n[4] \"piscisosseusb6d\"   \n\n\nLet’s retrieve the Transaction data by applying the filter type == \"Event.Transaction\" for our links data\nWe then perform a self-join on the transaction dataset on source column to get the respective city and fish column for each cargo delivery, filtering for only the two cities we observed earlier ‘City of Paackland’, ‘City of Lomark’ which snappersnatcher7b frequented.\n\nsuspected_transactions &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.Transaction\") %&gt;%\n  filter(!is.na(source) & !is.na(target))\n\n# Perform self-join to get the first target as \"city\" and the second target as \"fish\"\nsuspected_transactions_1 &lt;- suspected_transactions %&gt;%\n  group_by(source) %&gt;%\n  mutate(row_number = row_number()) %&gt;%\n  pivot_wider(names_from = row_number, values_from = target) %&gt;%\n  rename(city = `2`, fish = `1`) %&gt;%\n  rename(transaction_date = date) %&gt;%\n  filter(city %in% c('City of Paackland', 'City of Lomark') & transaction_date &lt; \"2035-05-09\") %&gt;%\n  select(source, fish, city, type, transaction_date)\n\nsuspected_transactions_1 &lt;- suspected_transactions_1 %&gt;%\n  inner_join(commodityfish, by = c(\"fish\" = \"id\"))\n\nNo duplicated transaction records were found after the self-join\n\n\nShow the code\nduplicated_transactions &lt;- suspected_transactions_1[duplicated(suspected_transactions_1$source), ]\nduplicated_transactions\n\n\n# A tibble: 0 × 16\n# Groups:   source [0]\n# ℹ 16 variables: source &lt;chr&gt;, fish &lt;chr&gt;, city &lt;chr&gt;, type.x &lt;chr&gt;,\n#   transaction_date &lt;date&gt;, type.y &lt;chr&gt;, type_original &lt;chr&gt;, namee &lt;chr&gt;,\n#   company &lt;chr&gt;, flag_country &lt;chr&gt;, Activities &lt;chr&gt;, tonnage &lt;dbl&gt;,\n#   length_overall &lt;dbl&gt;, raw_source &lt;chr&gt;, fish_species_present &lt;chr&gt;,\n#   kind &lt;chr&gt;\n\n\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlysnappersnatcher7b’s records then merge with suspected_transactions_1 dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with snappersnatcher7be’s harbor reporting to guess its cargo\n\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"snappersnatcher7be\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\nmerged_data &lt;- merge(suspected_transactions_1, harboureport_culprit, by = \"city\", all.x = TRUE)\n\n# Apply filter condition\nfiltered_transactions &lt;- merged_data %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(namee, fish, city,harboreporting_date,transaction_date, vessel)\n\n# Print the resulting dataframe\nprint(filtered_transactions)\n\n                     namee                  fish              city\n1 Cod/Gadus n.specificatae gadusnspecificatae4ba    City of Lomark\n2 Cod/Gadus n.specificatae gadusnspecificatae4ba    City of Lomark\n3 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n4 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n5 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n6 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n7 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n8 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n  harboreporting_date transaction_date             vessel\n1          2035-03-20       2035-03-17 snappersnatcher7be\n2          2035-03-20       2035-03-17 snappersnatcher7be\n3          2035-05-09       2035-05-06 snappersnatcher7be\n4          2035-05-09       2035-05-06 snappersnatcher7be\n5          2035-05-09       2035-05-06 snappersnatcher7be\n6          2035-05-09       2035-05-08 snappersnatcher7be\n7          2035-05-09       2035-05-08 snappersnatcher7be\n8          2035-05-09       2035-05-08 snappersnatcher7be\n\n\nWe have concluded a few details from this observation: snappersnatcher7be is only possible to be carrying these cargo:\n\n“Cod/Gadus n.specificatae” in around 20th March and\n“Wrasse/Labridae n.refert” in around 8th May\n\n\nprint(unique(filtered_transactions$namee))\n\n[1] \"Cod/Gadus n.specificatae\" \"Wrasse/Labridae n.refert\"\n\n\nWe found its transportation activities suspicious as it spent quite amount of time around “Ghoti Preserve”: - \"Nav 1\": 17 occurences - \"Nav 2\": 7 occurences\nHowever, under legit circumstances to fish species of “Wrasse/Labridae n.refert”, there’s few relevant occurences: - \"Nav C\": 10 occurences - \"Wrasse Beds\": 3 occurences\n\ntransponder_culprit &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"snappersnatcher7be\",\n         time &lt;= \"2035-05-09\",\n         time &gt;= \"2035-04-09\")\n\ncount_unique_categories(transponder_culprit, 'source') \n\n**source**\n\n        Cod Table         Exit East             Nav 2             Nav C \n               38                18                17                10 \n            Nav 1    City of Lomark       Wrasse Beds City of Paackland \n                7                 5                 3                 1 \n\n\n\n\n\n# Call the function with multiple region names\ncommodity_fish_ids &lt;- get_commodity_fish_ids(\"Don Limpet Preserve\")\nprint(commodity_fish_ids)\n\n[1] \"thunnininveradb7\" \"piscesfrigus900\"  \"habeaspisces4eb\"  \"piscessatisb87\"  \n[5] \"piscesfoetidaae7\""
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-1-eda",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-1-eda",
    "title": "Take Home Exercise 3",
    "section": "Task 2 (part 1) : EDA",
    "text": "Task 2 (part 1) : EDA\n\nFilter and Prepare DataConstruct the GraphInteractive VIsualisation\n\n\n\nExtracting Commodity Fish Data\nThis code segment focuses on filtering and preparing data for exploratory data analysis (EDA), particularly concerning commodity fish species in specific regions. It utilizes several packages within the tidyverse ecosystem.\nFirstly, the dplyr package is employed for data manipulation tasks. Two main operations are performed:\n\nFiltering Commodity Fish Data: The filter() function is used to extract rows from the mc2_nodes dataframe where the type is “Entity.Commodity.Fish”. This isolates data relevant to commodity fish species.\nExtracting Fish Species Data: Another subset of data is extracted for locations (“Entity.Location.Region” type) and processed to extract individual fish species. This involves several steps:\n\nThe filter() function extracts rows where the type is “Entity.Location.Region”.\nThe mutate() function modifies the data, removing unnecessary characters from the “fish_species_present” column and splitting the string into individual fish species using regular expressions (str_remove_all() and str_split()).\nThe unnest() function expands the list of fish species.\nFurther data cleaning is done with mutate() and rename() functions to ensure consistency and readability.\n\n\nFollowing data preparation, a function named get_commodity_fish_ids() is defined. This function retrieves commodity fish IDs for specific regions. It takes optional arguments for regions and utilizes the preprocessed fishspecies_expanded dataframe to filter and extract relevant fish species IDs based on specified regions.\n\n\nShow the code\ncommodityfish &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Commodity.Fish\")\n\n# Extract and transform Fish Species data\nfishspecies_expanded &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Location.Region\") %&gt;%\n  mutate(Fish_Species = str_remove_all(fish_species_present, 'c\\\\(|\\\\)|\"')) %&gt;%\n  mutate(Fish_Species = str_split(Fish_Species, \",\\\\s*\")) %&gt;%\n  unnest(Fish_Species) %&gt;%\n  mutate(Fish_Species = str_trim(Fish_Species)) %&gt;%\n  rename(Region = id)\n\n# Join with Commodity Fish data\nfishspecies_expanded &lt;- fishspecies_expanded %&gt;%\n  left_join(commodityfish, by = c(\"Fish_Species\" = \"namee\")) %&gt;%\n  select(Region, Fish_Species, id)\n\n# Function to get commodity fish IDs for specific regions\nget_commodity_fish_ids &lt;- function(..., regions = NULL) {\n  fishspecies_expanded %&gt;%\n    filter(Region %in% c(..., regions)) %&gt;%\n    pull(id)\n}\n\n\n\n\nPreparing Harbor Report Data.\nThis code filters data from mc2_links_prep to isolate harbor report events involving particular vessels (“snappersnatcher7be” and “roachrobberdb6”). It renames columns for clarity and selects only relevant columns, focusing on the city, vessel, event type, and reporting date. Overall, it streamlines the extraction and organization of data crucial for analyzing harbor activities related to specific vessels.\n\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\n\nProcessing Transaction Data\nRetrieve and process transaction data to identify suspicious transactions.\nLet’s retrieve the Transaction data by applying the filter type == \"Event.Transaction\" for our links data\nWe then perform a self-join on the transaction dataset on source column to get the respective city and fish column for each cargo delivery, filtering for only the two cities we observed earlier ‘City of Paackland’, ‘City of Lomark’ which snappersnatcher7b frequented.\n\n# Retrieve and process transaction data\ntransactions &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.Transaction\") %&gt;%\n  filter(!is.na(source) & !is.na(target)) %&gt;%\n  group_by(source) %&gt;%\n  mutate(row_number = row_number()) %&gt;%\n  pivot_wider(names_from = row_number, values_from = target) %&gt;%\n  rename(city = `2`, fish = `1`) %&gt;%\n  rename(transaction_date = date) %&gt;%\n  select(source, fish, city, type, transaction_date) %&gt;%\n  inner_join(commodityfish, by = c(\"fish\" = \"id\"))\n\nNo duplicated transaction records were found after the self-join\n\n\nShow the code\nduplicated_transactions &lt;- transactions[duplicated(transactions$source), ]\nduplicated_transactions\n\n\n# A tibble: 0 × 15\n# Groups:   source [0]\n# ℹ 15 variables: source &lt;chr&gt;, fish &lt;chr&gt;, city &lt;chr&gt;, type.x &lt;chr&gt;,\n#   transaction_date &lt;date&gt;, type.y &lt;chr&gt;, type_original &lt;chr&gt;, namee &lt;chr&gt;,\n#   company &lt;chr&gt;, flag_country &lt;chr&gt;, Activities &lt;chr&gt;, tonnage &lt;dbl&gt;,\n#   length_overall &lt;dbl&gt;, fish_species_present &lt;chr&gt;, kind &lt;chr&gt;\n\n\n\n\nFiltering and Preparing Nodes and Links\nThis code segment filters and prepares data from mc2_nodes and mc2_links dataframes, focusing on specific types of entities such as vessels, points, cities, and regions, while excluding vessels not associated with “SouthSeafood Express Corp”. It further filters mc2_links data to retain only transport events, transactions, and harbor reports. Then, it extracts relevant node IDs and filters edges to ensure consistency, removing any missing nodes from the filtered links. Overall, this process ensures that the data is tailored for subsequent analysis, particularly in the context of transportation and harbor activities involving specific entities.\n\n\nShow the code\n# Filter and prepare nodes\nmc2_nodes_suspect &lt;- mc2_nodes %&gt;%\n  filter(type %in% c('Entity.Vessel', 'Entity.Location.Point', 'Entity.Location.City', 'Entity.Location.Region')) %&gt;%\n  filter(!(type == 'Entity.Vessel' & company != \"SouthSeafood Express Corp\"))\n\n# Filter and prepare nodes\nmc2_links_filtered &lt;- mc2_links %&gt;%\n  filter(type %in% c('Event.TransportEvent.TransponderPing','Event.Transaction',\"Event.HarborReport\"))\n\n# Extract relevant node IDs\nfiltered_node_ids &lt;- mc2_nodes_suspect$id\n\n# Filter and prepare edges\nmc2_links_suspect &lt;- mc2_links_filtered %&gt;%\n  filter(source %in% filtered_node_ids & target %in% filtered_node_ids)\n\n# Ensure no missing nodes in the filtered links\nmissing_nodes &lt;- setdiff(unique(c(mc2_links_suspect$source, mc2_links_suspect$target)), mc2_nodes_suspect$id)\nif(length(missing_nodes) &gt; 0) {\n  mc2_links_suspect &lt;- mc2_links_suspect %&gt;%\n    filter(!source %in% missing_nodes & !target %in% missing_nodes)\n}\n\n\n\n\n\nThis code block utilizes the tidygraph package to construct a graph (mc2_graph) with filtered nodes and edges from the mc2_nodes_suspect and mc2_links_suspect dataframes, respectively. Here’s a brief summary:\n\nCreating Graph: The tbl_graph() function from tidygraph constructs a graph using the filtered nodes and edges, specifying it as a directed graph (directed = TRUE).\nCentrality Metrics: Three centrality metrics—betweenness centrality, closeness centrality, and degree centrality—are calculated for each node using the centrality_betweenness(), centrality_closeness(), and centrality_degree() functions, respectively.\n\n\n\nShow the code\n# Create the graph with filtered nodes and edges\nmc2_graph &lt;- tbl_graph(nodes = mc2_nodes_suspect, edges = mc2_links_suspect, directed = TRUE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness(),\n         degree_centrality = centrality_degree())\n\n\nThis code block filters the mc2_graph to include only nodes with edges, then visualizes the filtered graph using the ggraph package. The size of nodes corresponds to their degree centrality, and their color indicates their type. Node labels are added with geom_node_text(), and colors are customized for different node types. The visualization provides insights into the activities of SouthSeafood Express Corp, with a focus on different types of entities and their centrality within the network.\n\n\nShow the code\n# Filter the graph to include only nodes with edges\nmc2_graph_with_edges &lt;- mc2_graph %&gt;%\n  filter(!node_is_isolated())\n\n# Visualization with filtered nodes\nmc2_graph_with_edges %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5), show.legend = FALSE) +\n  geom_node_point(aes(\n    size = degree_centrality,\n    color = type,\n    alpha = 0.3)) +\n  geom_node_text(aes(label = id), repel = TRUE, size = 3, vjust = 1.5) +  # Add labels to nodes\n  scale_size_continuous(range = c(1, 10)) +\n  scale_color_manual(values = c(\"Entity.Vessel\" = \"blue\", \n                                \"Entity.Location.Point\"= \"red\",\n                                \"Entity.Location.Region\" =\"green\",\n                                \"Entity.Location.City\" = \"lightblue\"\n                                )) +\n  labs(title = \"SouthSeafood Express Corp's Activities\",\n       color = \"Node Type\",\n       size = \"Degree Centrality\")\n\n\n\n\n\n\n\nThis code aggregates edge data from mc2_links_suspect, filters out isolated nodes, and prepares the data for visualization. It utilizes the visNetwork function from the visNetwork package to create an interactive network visualization. Nodes and edges are represented based on the filtered data, with options for selecting nodes by type and highlighting nearest nodes. The resulting visualization offers insights into the network structure and relationships among different entities involved in the analyzed activities.\n\n\nShow the code\n# Aggregate edges data\nmc2_links_suspect &lt;- mc2_links_suspect %&gt;%\n  left_join(mc2_nodes_suspect, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = source) %&gt;%\n  left_join(mc2_nodes_suspect, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = target) %&gt;%\n  group_by(from, to) %&gt;%\n  summarise(weight = sum(weights)) %&gt;%\n  filter(from != to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\nconnected_nodes &lt;- unique(c(mc2_links_suspect$from, mc2_links_suspect$to))\n\n# Filter out isolated nodes\nmc2_nodes_suspect &lt;- mc2_nodes_suspect %&gt;%\n  filter(id %in% connected_nodes) %&gt;%\n  rename(group = type) %&gt;%\n  mutate(label = ifelse(group %in% c('Entity.Vessel', 'Entity.Location.Point', 'Entity.Location.City',\"Entity.Location.Region\"), id, NA)) %&gt;%\n  group_by(company) %&gt;%\n  mutate(id1 = if_else(group == \"Entity.Vessel\" & company != \"\" & !is.na(company),\n                       paste0(company, row_number()),\n                       if_else(group == \"Entity.Vessel\" & (company == \"\" | is.na(company)), id, NA_character_)),\n         id1 = if_else(group != \"Entity.Vessel\", id, id1)) %&gt;%\n  ungroup()\n\n\n### Visualize the Graph\n\n# Visualize the resulting graph\nvisNetwork(mc2_nodes_suspect, mc2_links_suspect) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1),\n             nodesIdSelection = TRUE,\n             selectedBy = \"type\")  # Add type dropdown"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-2-deep-investigations-into-southseafood-express-corp",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-2-deep-investigations-into-southseafood-express-corp",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "Task 2 (part 2) : Deep Investigations into “SouthSeafood Express Corp”",
    "text": "Task 2 (part 2) : Deep Investigations into “SouthSeafood Express Corp”\n\"SouthSeafood Express Corp\"was likely caught to be just after \"2035-05-09\" which happened to be it’s last harbor report.\n\n\nShow the code\ncommodityfish &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Commodity.Fish\")\n\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\ndate_caught &lt;- max(harboureport_culprit$harboreporting_date)\nprint(date_caught)\n\n\n[1] \"2035-05-09\"\n\n\n\nDeep Investigation into snappersnatcher7bWhat type of fishes are in these fishing grounds?Narrowing down the Transaction dataAnalysing the HarborReport and Transaction data togetherSuspicious Findings\n\n\nNow let’s derive a function to retrieve the unique fishes found in the regions\n\n\nShow the code\n# Getting the Fish species in Regions the transformation of Fish_Species\nfishspecies_expanded &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Location.Region\") %&gt;%\n  mutate(Fish_Species = str_remove_all(fish_species_present, 'c\\\\(|\\\\)|\"')) %&gt;%\n  mutate(Fish_Species = str_split(Fish_Species, \",\\\\s*\")) %&gt;%\n  unnest(Fish_Species) %&gt;%\n  mutate(Fish_Species = str_trim(Fish_Species)) %&gt;%\n  rename(Region = id)\n\n# Joining the dataframes\nfishspecies_expanded &lt;- fishspecies_expanded %&gt;%\n  left_join(commodityfish, by = c(\"Fish_Species\" = \"namee\")) %&gt;%\n  select(Region, Fish_Species, id)\n\n# Define the function to get commodity fish IDs for specific regions\nget_commodity_fish_ids &lt;- function(..., regions = NULL) {\n  fishspecies_expanded %&gt;%\n    filter(Region %in% c(..., regions)) %&gt;%\n    pull(id)\n}\n\n# Call the function with multiple region names\ncommodity_fish_ids &lt;- unique(get_commodity_fish_ids(\"Ghoti Preserve\", \"Don Limpet Preserve\"))\nprint(commodity_fish_ids)\n\n\n[1] \"labridaenrefert9be\" \"habeaspisces4eb\"    \"piscessatisb87\"    \n[4] \"piscisosseusb6d\"    \"thunnininveradb7\"   \"piscesfrigus900\"   \n[7] \"piscesfoetidaae7\"  \n\n\n\n\nFrom the EDA/ visualisation earlier, it seems “snappersnatcher7be” frequents - Locations: \"Nav1\", \"Nav2\" which is extremely near \"Ghoti Preserve\" and - Region: \"Wrasse Beds\" , \"Ghoti Preserve\", \"Cod Table\" - City: City of Paackland and City of Lomark\nIn \"Ghoti Preserve\", these are the fish species that commonly found. The names are as below:\n\n\nShow the code\n# Pull out the names of the fish species found in Ghoti Preserve\nunique_fish_species_ghoti &lt;- fishspecies_expanded %&gt;%\n  filter(Region == \"Ghoti Preserve\") %&gt;%\n  pull(Fish_Species) %&gt;%\n  unique()\n\n# Print the unique Fish_Species\nprint(unique_fish_species_ghoti)\n\n\n[1] \"Wrasse/Labridae n.refert\" \"Beauvoir/Habeas pisces\"  \n[3] \"Helenaa/Pisces satis\"     \"Offidiaa/Piscis osseus\"  \n\n\nThe ids are:\n\n# Call the function to get id of the fishes for Ghoti Preserve\ncommodity_fish_ids &lt;- get_commodity_fish_ids(\"Ghoti Preserve\")\nprint(commodity_fish_ids)\n\n[1] \"labridaenrefert9be\" \"habeaspisces4eb\"    \"piscessatisb87\"    \n[4] \"piscisosseusb6d\"   \n\n\n\n\nLet’s retrieve the Transaction data by applying the filter type == \"Event.Transaction\" for our links data\nWe then perform a self-join on the transaction dataset on source column to get the respective city and fish column for each cargo delivery, filtering for only the two cities we observed earlier ‘City of Paackland’, ‘City of Lomark’ which snappersnatcher7b frequented.\n\nsuspected_transactions &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.Transaction\") %&gt;%\n  filter(!is.na(source) & !is.na(target))\n\n# Perform self-join to get the first target as \"city\" and the second target as \"fish\"\nsuspected_transactions_1 &lt;- suspected_transactions %&gt;%\n  group_by(source) %&gt;%\n  mutate(row_number = row_number()) %&gt;%\n  pivot_wider(names_from = row_number, values_from = target) %&gt;%\n  rename(city = `2`, fish = `1`) %&gt;%\n  rename(transaction_date = date) %&gt;%\n  filter(city %in% c('City of Paackland', 'City of Lomark') & transaction_date &lt; \"2035-05-09\") %&gt;%\n  select(source, fish, city, type, transaction_date)\n\nsuspected_transactions_1 &lt;- suspected_transactions_1 %&gt;%\n  inner_join(commodityfish, by = c(\"fish\" = \"id\"))\n\nNo duplicated transaction records were found after the self-join\n\n\nShow the code\nduplicated_transactions &lt;- suspected_transactions_1[duplicated(suspected_transactions_1$source), ]\nduplicated_transactions\n\n\n# A tibble: 0 × 16\n# Groups:   source [0]\n# ℹ 16 variables: source &lt;chr&gt;, fish &lt;chr&gt;, city &lt;chr&gt;, type.x &lt;chr&gt;,\n#   transaction_date &lt;date&gt;, type.y &lt;chr&gt;, type_original &lt;chr&gt;, namee &lt;chr&gt;,\n#   company &lt;chr&gt;, flag_country &lt;chr&gt;, Activities &lt;chr&gt;, tonnage &lt;dbl&gt;,\n#   length_overall &lt;dbl&gt;, raw_source &lt;chr&gt;, fish_species_present &lt;chr&gt;,\n#   kind &lt;chr&gt;\n\n\n\n\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlysnappersnatcher7b’s records then merge with suspected_transactions_1 dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with snappersnatcher7be’s harbor reporting to guess its cargo\n\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"snappersnatcher7be\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\nmerged_data &lt;- merge(suspected_transactions_1, harboureport_culprit, by = \"city\", all.x = TRUE)\n\n# Apply filter condition\nfiltered_transactions &lt;- merged_data %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(namee, fish, city,harboreporting_date,transaction_date, vessel)\n\n# Print the resulting dataframe\nprint(filtered_transactions)\n\n                     namee                  fish              city\n1 Cod/Gadus n.specificatae gadusnspecificatae4ba    City of Lomark\n2 Cod/Gadus n.specificatae gadusnspecificatae4ba    City of Lomark\n3 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n4 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n5 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n6 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n7 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n8 Wrasse/Labridae n.refert    labridaenrefert9be City of Paackland\n  harboreporting_date transaction_date             vessel\n1          2035-03-20       2035-03-17 snappersnatcher7be\n2          2035-03-20       2035-03-17 snappersnatcher7be\n3          2035-05-09       2035-05-06 snappersnatcher7be\n4          2035-05-09       2035-05-06 snappersnatcher7be\n5          2035-05-09       2035-05-06 snappersnatcher7be\n6          2035-05-09       2035-05-08 snappersnatcher7be\n7          2035-05-09       2035-05-08 snappersnatcher7be\n8          2035-05-09       2035-05-08 snappersnatcher7be\n\n\n\n\nWe have concluded a few details from this observation: snappersnatcher7be is only possible to be carrying these cargo:\n\n“Cod/Gadus n.specificatae” in around 20th March and\n“Wrasse/Labridae n.refert” in around 8th May\n\n\nprint(unique(filtered_transactions$namee))\n\n[1] \"Cod/Gadus n.specificatae\" \"Wrasse/Labridae n.refert\"\n\n\nWe found its transportation activities suspicious as it spent quite amount of time around “Ghoti Preserve”: - \"Nav 1\": 17 occurences - \"Nav 2\": 7 occurences\nHowever, under legit circumstances to fish species of “Wrasse/Labridae n.refert”, there’s few relevant occurences: - \"Nav C\": 10 occurences - \"Wrasse Beds\": 3 occurences\n\ntransponder_culprit &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"snappersnatcher7be\",\n         time &lt;= \"2035-05-09\",\n         time &gt;= \"2035-04-09\")\n\ncount_unique_categories(transponder_culprit, 'source') \n\n**source**\n\n        Cod Table         Exit East             Nav 2             Nav C \n               38                18                17                10 \n            Nav 1    City of Lomark       Wrasse Beds City of Paackland \n                7                 5                 3                 1 \n\n\n\n\n\n\nDeep Investigation into \"roachrobberdb6\"\n\n# Call the function with multiple region names\ncommodity_fish_ids &lt;- get_commodity_fish_ids(\"Don Limpet Preserve\")\nprint(commodity_fish_ids)\n\n[1] \"thunnininveradb7\" \"piscesfrigus900\"  \"habeaspisces4eb\"  \"piscessatisb87\"  \n[5] \"piscesfoetidaae7\"\n\n\n:::"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-2-deep-investigations-into-snappersnatcher7b",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-2-deep-investigations-into-snappersnatcher7b",
    "title": "Take Home Exercise 3",
    "section": "Task 2 (part 2) : Deep Investigations into “snappersnatcher7b”",
    "text": "Task 2 (part 2) : Deep Investigations into “snappersnatcher7b”\n\n1. Fish Species in Ghoti Preserve2. Suspicious Transactions3. Suspicious Findings\n\n\nFrom the EDA/ visualisation earlier, it seems \"snappersnatcher7be\" frequents:\n\nLocations: \"Nav1\", \"Nav2\" which is extremely near \"Ghoti Preserve\"\nRegion: \"Wrasse Beds\" , \"Ghoti Preserve\", \"Cod Table\"\nCity: City of Paackland and City of Lomark\n\nHence, let’s identify the fish species commonly found in the “Ghoti Preserve” region.\nIn \"Ghoti Preserve\", these are the fish species that commonly found. The names are as below:\n\n\nShow the code\n# Retrieve unique fish species in Ghoti Preserve\nunique_fish_species_ghoti &lt;- fishspecies_expanded %&gt;%\n  filter(Region == \"Ghoti Preserve\") %&gt;%\n  pull(Fish_Species) %&gt;%\n  unique()\n\n# Print the unique Fish_Species\nprint(unique_fish_species_ghoti)\n\n\n[1] \"Wrasse/Labridae n.refert\" \"Beauvoir/Habeas pisces\"  \n[3] \"Helenaa/Pisces satis\"     \"Offidiaa/Piscis osseus\"  \n\n\n\n\nMerge the transactions with HarborReport data to identify relevant suspicious transactions.\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlysnappersnatcher7b’s records then merge with transactions dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with snappersnatcher7be’s harbor reporting to guess its cargo\n\n\nShow the code\n# Retrieve HarborReport data for \"snappersnatcher7be\"\nharboureport_culprit&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"snappersnatcher7be\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\n# Merge with transactions and apply filter condition\nmerged_data &lt;- merge(transactions, harboureport_culprit, by = \"city\", all.x = TRUE)\n\n\nfiltered_transactions &lt;- merged_data %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(namee, fish, city,harboreporting_date,transaction_date, vessel)\n\n\n“Cod/Gadus n.specificatae” was filtered out as it is a commonly found in legal fishing areas. Then, we merged this filtered data with another dataframe named fishspecies_expanded based on a common column, namely “namee” and “Fish_Species” respectively.Finally, we extract unique regions from the merged data and prints them.\nThe output displays the unique regions found in the merged dataset, which are “Ghoti Preserve,” “Nemo Reef,” and “Wrasse Beds.” These are the likely fishing grounds the vessels should be found.\n\n\nShow the code\n# Filter out entries where namee is not \"Cod/Gadus n.specificatae\"\nfiltered_transactions &lt;- filtered_transactions %&gt;%\n  filter(namee != \"Cod/Gadus n.specificatae\")\n\n\njoined_data &lt;- merge(filtered_transactions, fishspecies_expanded, by.x = \"namee\", by.y = \"Fish_Species\", all.x = TRUE)\nunique_regions &lt;- unique(joined_data$Region)\nunique_regions\n\n\n[1] \"Ghoti Preserve\" \"Nemo Reef\"      \"Wrasse Beds\"   \n\n\nWe generate a timeline plot illustrating suspicious transactions and harbor reports associated with the vessel “snappersnatcher7be,” showcasing the relationship between transaction dates, cargo types, vessels, and cities involved.\nIt’s likely to have made transactions of cargo “Wrasse/Labridae n.refert” within thisdate range shown.\n\n\nShow the code\n# Create the timeline plot\nggplot(filtered_transactions)  +\n  geom_segment(aes(x = transaction_date, xend = harboreporting_date, y = namee, yend = namee, color = vessel), size = 1.5) +\n  geom_point(aes(x = transaction_date, y = namee, color = vessel, shape = city), size = 3) +\n  labs(title = \"Suspicious Transactions and Harbor Reports for snappersnatcher7be\", x = \"Date\", y = \"Cargo Type\") +\n  theme_minimal() +\n  scale_color_discrete(name = \"Vessel\") +\n  scale_shape_discrete(name = \"City\") +  # Add legend for city\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nFrom our observations, “snappersnatcher7be” is likely carrying the following cargo:\n\n“Cod/Gadus n.specificatae” around 20th March and\n“Wrasse/Labridae n.refert” around 8th May\n\n\n\nShow the code\nprint(unique(filtered_transactions$namee))\n\n\n[1] \"Wrasse/Labridae n.refert\"\n\n\nAdditionally, we found its transportation activities suspicious due to its frequent visits to “Ghoti Preserve”:\n\n\"Nav 1\": 17 occurences\n\"Nav 2\": 7 occurences\n\nFor legitimate occurrences related to “Wrasse/Labridae n.refert”, there’s fewer:\n\n\"Nav C\": 10 occurences\n\"Wrasse Beds\": 3 occurences\n\n\n\nShow the code\n# Retrieve TransponderPing data for \"snappersnatcher7be\"\ntransponder_culprit &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"snappersnatcher7be\",\n         time &lt;= \"2035-05-09\",\n         time &gt;= \"2035-04-09\")\n\n# Count unique categories in the 'source' column\ncount_unique_categories(transponder_culprit, 'source') \n\n\n**source**\n\n        Cod Table         Exit East             Nav 2             Nav C \n               37                18                17                10 \n            Nav 1    City of Lomark       Wrasse Beds City of Paackland \n                7                 5                 3                 1 \n\n\n\nBar Plot for Suspicious and Legitimate Transportation Activities\nWe plotted a bar plot illustrating transportation activities associated with the entity “snappersnatcher7be,” distinguishing between suspicious and legitimate locations as described above.\n\n\nShow the code\n# Data for transportation activities\nlocation_counts &lt;- transponder_culprit %&gt;%\n  filter(!source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Type = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",\n    TRUE ~ \"Legitimate\"\n  ))\n\n# Reorder Location factor levels so \"Suspicious\" locations appear at the top\nlocation_counts &lt;- location_counts %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Type, decreasing = TRUE)])))\n\n# Bar plot for transportation activities\nggplot(location_counts, aes(x = Occurrences, y = Location, fill = Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Transportation Activities of snappersnatcher7be\", x = \"Number of Occurrences\", y = \"Location\") +\n  scale_fill_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nGeographical Plot for Suspicious and Legitimate Transportation Activities\nBelow, is the geographical representation of what we found to be legitmate and suspicious locations for the vessel.\n\n\nShow the code\nlocation_counts &lt;- transponder_culprit %&gt;%\n  filter(source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"Nav 1\", \"Nav 2\", \"Ghoti Preserve\", \"Exit East\", \"Nav C\", \"Wrasse Beds\", \"Don Limpet Preserve\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Marked = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",   TRUE ~ \"Legitimate\"\n  )) %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Marked, decreasing = TRUE)])))  # Reorder Location factor levels\n\n# Merge location counts with geo data\ngeo_data_0 &lt;- left_join(geo_data, location_counts, by = c(\"id\" = \"Location\"))\n\n# Extract coordinates from geometry data\ncoords_0 &lt;- st_coordinates(st_centroid(geo_data_0))\n\n# Add coordinates to the geo_data\ngeo_data_0$Longitude &lt;- coords_0[,1]\ngeo_data_0$Latitude &lt;- coords_0[,2]\n\n\n# Filter for specific IDs to label\nlabel_ids_0 &lt;- c('Cod Table', 'Exit East', 'City of Paackland', 'City of Lomark', 'Nav 1', 'Nav 2', 'Ghoti Preserve', 'Exit East', 'Nav C', 'Wrasse Beds', 'Don Limpet Preserve')\ngeo_data_labels_0 &lt;- geo_data_0 %&gt;%\n  filter(id %in% label_ids_0)\n\n# Set plot size (for RStudio or other environments that support resizing)\noptions(repr.plot.width = 10, repr.plot.height = 8)\n\n# Geographical plot with labels\nggplot() +\n  geom_sf(data = geo_data_labels_0, aes(geometry = geometry, color = Marked)) +\n  geom_text(data = geo_data_labels_0 , aes(x = Longitude, y = Latitude, label = id), size = 2, color = \"black\", fontface = \"bold\") +\n  scale_color_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  labs(title = \"Geographical Plot of snappersnatcher7be Activities\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 16),  # Enlarge title\n        legend.title = element_text(size = 12),  # Enlarge legend title\n        legend.text = element_text(size = 10),  # Enlarge legend text\n        axis.text = element_text(size = 10),  # Enlarge axis text\n        axis.title = element_text(size = 12))  # Enlarge axis title"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-3-deep-investigations-into-roachrobberdb6",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-3-deep-investigations-into-roachrobberdb6",
    "title": "Take Home Exercise 3",
    "section": "Task 2 (part 3) : Deep Investigations into “roachrobberdb6”",
    "text": "Task 2 (part 3) : Deep Investigations into “roachrobberdb6”\n\n1. Suspicious Transactions2. No Suspicious Findings\n\n\nMerge the transactions with HarborReport data to identify relevant suspicious transactions.\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlyroachrobberdb6’s records then merge with transactions dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with roachrobberdb6’s harbor reporting to guess its cargo\n\n\nShow the code\n# Retrieve HarborReport data for \"roachrobberdb6\"\nharboureport_culprit1&lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"roachrobberdb6\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\n# Merge with transactions and apply filter condition\nmerged_data1 &lt;- merge(transactions, harboureport_culprit1, by = \"city\", all.x = TRUE)\n\n\nfiltered_transactions1 &lt;- merged_data1 %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(namee, fish, city,harboreporting_date,transaction_date, vessel)\n\n\n\n# Filter out entries where namee is not \"Cod/Gadus n.specificatae\"\nfiltered_transactions1 &lt;- filtered_transactions1 %&gt;%\n  filter(namee != \"Cod/Gadus n.specificatae\")\n\n\njoined_data &lt;- merge(filtered_transactions1, fishspecies_expanded, by.x = \"namee\", by.y = \"Fish_Species\", all.x = TRUE)\nunique_regions &lt;- unique(joined_data$Region)\nunique_regions\n\n[1] \"Tuna Shelf\"     \"Ghoti Preserve\" \"Wrasse Beds\"    \"Nemo Reef\"     \n\n\nWe generate a timeline plot illustrating suspicious transactions and harbor reports associated with the vessel “roachrobberdb6,” showcasing the relationship between transaction dates, cargo types, vessels, and cities involved.\n\n\nShow the code\n# Create the timeline plot\nggplot(filtered_transactions1) +\n  geom_segment(aes(x = transaction_date, xend = harboreporting_date, y = namee, yend = namee, color = vessel), size = 1.5) +\n  geom_point(aes(x = transaction_date, y = namee, color = vessel, shape = city), size = 3) +\n  labs(title = \"Suspicious Transactions and Harbor Reports for roachrobberdb6\", x = \"Date\", y = \"Cargo Type\") +\n  theme_minimal() +\n  scale_color_discrete(name = \"Vessel\") +\n  scale_shape_discrete(name = \"City\") +  # Add legend for city\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nFrom our observations previously, “roachrobberdb6” is likely carrying the following cargo:\n\n“Wrasse/Labridae n.refert” around February and April\n“Harland/Piscis sapidum” in April\n\n\n\nShow the code\nprint(unique(filtered_transactions1$namee))\n\n\n[1] \"Wrasse/Labridae n.refert\" \"Harland/Piscis sapidum\"  \n\n\nWe did not manage to find its fishing activities suspicious between the period however for the date range. It is likely not to be suspicious.\n\n\"Nav C\": 38 occurences\n\"Wrasse Beds\": 42 occurences\n\n\n\nShow the code\n# Retrieve TransponderPing data for \"roachrobberdb6\"\ntransponder_culprit1 &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"roachrobberdb6\",\n         time &lt;= \"2035-04-05\",\n         time &gt;= \"2035-03-20\")\n\n# Count unique categories in the 'source' column\ncount_unique_categories(transponder_culprit1, 'source') \n\n\n**source**\n\n   Wrasse Beds          Nav C City of Himark City of Lomark \n            40             35              2              2 \n\n\n\nBar Plot for Suspicious and Legitimate Transportation Activities\nWe plotted a bar plot illustrating transportation activities associated with the entity “roachrobberdb6,” distinguishing between suspicious and legitimate locations as described above.\n\n\nShow the code\n# Data for transportation activities\nlocation_counts1 &lt;- transponder_culprit1 %&gt;%\n  filter(!source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"City of Himark\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Type = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",\n    TRUE ~ \"Legitimate\"\n  ))\n\n# Reorder Location factor levels so \"Suspicious\" locations appear at the top\nlocation_counts1 &lt;- location_counts1 %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Type, decreasing = TRUE)])))\n\n# Bar plot for transportation activities\nggplot(location_counts1, aes(x = Occurrences, y = Location, fill = Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Transportation Activities of roachrobberdb6\", x = \"Number of Occurrences\", y = \"Location\") +\n  scale_fill_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nGeographical Visualisation\nBelow, is the geographical representation of what we found to be legitmate and suspicious locations for the vessel.\n\n\nShow the code\n# Create location_counts1 with the Marked column\nlocation_counts1 &lt;- transponder_culprit1 %&gt;%\n  filter(source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"Nav 1\", \"Nav 2\", \"Ghoti Preserve\", \"Exit East\", \"Nav C\", \"Wrasse Beds\", \"Don Limpet Preserve\",\"Nemo Preserve\",\"Tuna Shelf\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Marked = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",   \n    TRUE ~ \"Legitimate\"\n  )) %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Marked, decreasing = TRUE)])))  # Reorder Location factor levels\n\n# Merge location counts with geo_data to include the Marked column\ngeo_data_1 &lt;- left_join(geo_data, location_counts1, by = c(\"id\" = \"Location\"))\n\n# Extract coordinates from geometry data\ncoords_1 &lt;- st_coordinates(st_centroid(geo_data_1))\n# Warning: st_centroid assumes attributes are constant over geometries\n\n# Add coordinates to the geo_data\ngeo_data_1$Longitude &lt;- coords_1[,1]\ngeo_data_1$Latitude &lt;- coords_1[,2]\n\n# Filter for specific IDs to label\nlabel_ids &lt;- c('Cod Table', 'Exit East', 'City of Paackland', 'City of Lomark', 'Nav 1', 'Nav 2', 'Ghoti Preserve', 'Exit East', 'Nav C', \"Wrasse Beds\", \"Don Limpet Preserve\",\"Nemo Preserve\",\"Tuna Shelf\")\ngeo_data_labels_1 &lt;- geo_data_1 %&gt;%\n  filter(id %in% label_ids)\n\n# Set plot size (for RStudio or other environments that support resizing)\noptions(repr.plot.width = 10, repr.plot.height = 8)\n\n# Geographical plot with labels\nggplot() +\n  geom_sf(data = geo_data_labels_1, aes(geometry = geometry, color = geo_data_labels_1$Marked)) +\n  geom_text(data = geo_data_labels_1 , aes(x = Longitude, y = Latitude, label = id), size = 2, color = \"black\", fontface = \"bold\") +\n  scale_color_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  labs(title = \"Geographical Plot of roachrobberdb6 Activities\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 16),  # Enlarge title\n        legend.title = element_text(size = 12),  # Enlarge legend title\n        legend.text = element_text(size = 10),  # Enlarge legend text\n        axis.text = element_text(size = 10),  # Enlarge axis text\n        axis.title = element_text(size = 12))  # Enlarge axis title"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-insights-from-visualisations",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-insights-from-visualisations",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "Task 2 (part 4) : Insights from Visualisations",
    "text": "Task 2 (part 4) : Insights from Visualisations\n\n\n\n\n\n\nNote\n\n\n\nSuspicious Movement and Catch Contents of SouthSeafood Express Corp\n\nMovement Patterns:\nThe vessel “snappersnatcher7be” shows frequent visits to suspicious locations such as “Nav 1” (17 occurrences) and “Nav 2” (7 occurrences), which are near “Ghoti Preserve”.\nCatch Contents:\nThe vessel “snappersnatcher7be” is suspected of carrying cargo such as “Wrasse/Labridae n.refert” which is found only in “Ghoti Preserve” , “Wrasse Beds” and “Nemo Reef.” However, our visualisation reveals that it does not venture near “Nemo Reef” and it spends an equal amount of time at “Wrasse Beds” and locations near “Ghoti Preserve”\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTiming and Locations of Illegal Fishing Activities for SouthSeafood Express Corp\n\nTimeframe of Illegal Activities:\nAround May 8th, “snappersnatcher7be” is likely involved in suspicious cargo activities involving “Wrasse/Labridae n.refert”. Hence, we suspect it conducted illegal fishing in the month previous.\nLocations of Illegal Fishing:\nThe vessel’s frequent visits to “Nav 1” and “Nav 2” suggest these locations are hotspots for illegal activities.\nThese locations are close to “Ghoti Preserve”, a region known for fish species like “Wrasse/Labridae n.refert”.\n\n\n\n\n#### Last HarborReport of SouthSeafood Express Corp\"\ndate_caught &lt;- max(harboureport_culprit$harboreporting_date)\nprint(date_caught)\n\n[1] \"2035-05-09\"\n\n\n\"SouthSeafood Express Corp\"was likely caught just after \"2035-05-09\" as that happened to be it’s last harbor report."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-transshipment-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-transshipment-analysis",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "Task 2 (part 4) : Transshipment Analysis",
    "text": "Task 2 (part 4) : Transshipment Analysis\n\n1. Extract Movement Data\nFirst, we extract vessel movement data from the mc2_links_prep dataset. Specifically, we are filtering the data to retain only the transponder ping events, which represent instances of vessel movement. Each ping event is associated with a location, vessel ID, and timestamp.\n\n\nShow the code\n# Extract transponder ping data for vessel movements\ntransponder_pings &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\") %&gt;%\n  rename(location = source, vessel = target, ping_date = ping_date) %&gt;%\n  mutate(ping_id = row_number())  # Add a unique identifier for each row\n\n\n\n\n2. Identify Vessel Pairs at the Same Location and Time\nNext, we’re identifying pairs of vessels that are at the same location at the same time. This is achieved through a self-join operation on the transponder ping data. After ensuring that the same vessel is not paired with itself, we select distinct pairs to avoid duplicates.\n\n\nShow the code\n# Perform a self-join to find pairs of vessels at the same location and time\nvessel_pairs &lt;- transponder_pings %&gt;%\n  inner_join(transponder_pings, by = c(\"location\", \"ping_date\")) %&gt;%\n  filter(ping_id.x &lt; ping_id.y) %&gt;%  # Ensure we do not pair the same id \n  filter(vessel.x != vessel.y) %&gt;%  # Ensure we do not pair the same vessel\n  \n  select(\n    vessel1 = vessel.x,\n    vessel2 = vessel.y,\n    location,\n    ping_date\n  )\n\n\n\n\n3. Aggregate and Analyze Transshipments\nIn this section, we aggregate and analyze the transshipment data. We aggregate the count of vessel pairs by date. Then, we join the vessel pairs with company information to identify the companies involved in transshipments. Finally, we group the transshipment data by company pairs and date to analyze the frequency of transshipments.\n\n\nShow the code\n# Aggregate the count of vessel pairs by date\ntransshipments_count &lt;- vessel_pairs %&gt;%\n  mutate(date = as.Date(ping_date)) %&gt;%\n  group_by(date) %&gt;%\n  summarise(transshipments = n())\n\n# Join vessel_pairs with mc2_nodes to get the company information\nvessel_pairs_with_company &lt;- vessel_pairs %&gt;%\n  left_join(mc2_nodes %&gt;% select(id, company), by = c(\"vessel1\" = \"id\")) %&gt;%\n  rename(company1 = company) %&gt;%\n  left_join(mc2_nodes %&gt;% select(id, company), by = c(\"vessel2\" = \"id\")) %&gt;%\n  rename(company2 = company)\n\n# Group vessel pairs by company\ntransshipments_by_company &lt;- vessel_pairs_with_company %&gt;%\n  filter(company1 == company2) %&gt;%\n  mutate(date = as.Date(ping_date)) %&gt;%  # Ensure date column is present\n  mutate(transshipment = ifelse(duplicated(cbind(company1, company2, date)) | \n                                duplicated(cbind(company2, company1, date)), 0, 1)) %&gt;%  # Set transshipments to 0 if duplicated\n  group_by(company1, company2, date) %&gt;%\n  summarise(transshipments = sum(transshipment)) %&gt;%\n  ungroup()\n\n# Filter and summarise transshipments for vessel pairs belonging to the same company\nsame_company_transshipments &lt;- transshipments_by_company %&gt;%\n  group_by(company1, company2) %&gt;%\n  summarise(transshipments = sum(transshipments)) %&gt;%\n  ungroup()\n\n\n\n\n4. Visualize Transshipment Data for Specific Company\nFinally, we’re visualizing the transshipment data for a specific company, “SouthSeafood Express Corp”. This plot shows the timeline of transshipments for vessel pairs belonging to this company.\n\n\nShow the code\n# Filter vessel pairs belonging to the same company \"SouthSeafood Express Corp\"\nSouthSeafood_transshipments &lt;- transshipments_by_company %&gt;%\n  filter(company1 == \"SouthSeafood Express Corp\" & company2 == \"SouthSeafood Express Corp\")\n\n\n\n\nShow the code\n# Create a plot\nggplot(SouthSeafood_transshipments, aes(x = date, y = transshipments)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Transshipments for Vessel Pairs of SouthSeafood Express Corp\",\n       x = \"Date\",\n       y = \"Transshipments Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-5-insights-from-visualisations",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-5-insights-from-visualisations",
    "title": "Take Home Exercise 3",
    "section": "Task 2 (part 5) : Insights from Visualisations",
    "text": "Task 2 (part 5) : Insights from Visualisations\n\n\n\n\n\n\nNote\n\n\n\nSuspicious Movement and Catch Contents of SouthSeafood Express Corp\n\nMovement Patterns:\nThe vessel “snappersnatcher7be” shows frequent visits to suspicious locations such as “Nav 1” (17 occurrences) and “Nav 2” (7 occurrences), which are near “Ghoti Preserve”.\nThe visualization illustrates a significant number of transshipment events involving vessels associated with “SouthSeafood Express Corp.” These events, occurring over a period of time, indicate a pattern of coordinated activities suggestive of illicit practices.The plotted data reveals a consistent trend of transshipment occurrences over time, which deviates significantly from normal maritime operations. The frequency and pattern of these events suggest deliberate efforts to transfer goods between vessels, potentially for illegal purposes such as smuggling or avoiding regulatory oversight.\nCatch Contents:\nThe vessel “snappersnatcher7be” is suspected of carrying cargo such as “Wrasse/Labridae n.refert” which is found only in “Ghoti Preserve” , “Wrasse Beds” and “Nemo Reef.” However, our visualisation reveals that it does not venture near “Nemo Reef” and it spends an equal amount of time at “Wrasse Beds” and locations near “Ghoti Preserve”\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTiming and Locations of Illegal Fishing Activities for SouthSeafood Express Corp\n\nTimeframe of Illegal Activities:\nAround May 8th, “snappersnatcher7be” is likely involved in suspicious cargo activities involving “Wrasse/Labridae n.refert”. Hence, we suspect it conducted illegal fishing in the month previous.\nLocations of Illegal Fishing:\nThe vessel’s frequent visits to “Nav 1” and “Nav 2” suggest these locations are hotspots for illegal activities.\nThese locations are close to “Ghoti Preserve”, a region known for fish species like “Wrasse/Labridae n.refert”.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSuspicious vessel tragejctories found likely to indicate transshipping\n\nThe trajectories of both vessels belonging to SouthSeafood Express Corp appear to intersect at specific points in time, particularly at Nav C. This presents a compelling indication of transshipment taking place."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-3-part-1",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-3-part-1",
    "title": "Take Home Exercise 3: WORK IN PROGRESS",
    "section": "Task 3 (part 1) :",
    "text": "Task 3 (part 1) :\n\n\nShow the code\ntransshipments_by_company %&gt;%\n  group_by(company1, company2) %&gt;%\n  summarise(total_transshipments = sum(transshipments)) %&gt;%\n  arrange(desc(total_transshipments)) %&gt;%\n  top_n(10) %&gt;%\n  ggplot(aes(x = reorder(company1, total_transshipments), y = total_transshipments)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Intra-Company Transshipment Activity\",\n       x = \"Company\",\n       y = \"Total Transshipments\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\n\n\n\n\n\n\nShow the code\n# Extract transponder ping data for vessel movements\ntransponder_pings &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\") %&gt;%\n  rename(location = source, vessel = target, ping_date = ping_date) %&gt;%\n  mutate(ping_id = row_number(),  # Add a unique identifier for each row\n         location = case_when(\n           location == \"City of Haacklee\" ~ \"Haacklee\",\n           location == \"City of Himark\" ~ \"Himark\",\n           location == \"City of Port Grove\" ~ \"Port Grove\",\n           location == \"City of Lomark\" ~ \"Lomark\",\n           location == \"City of Paackland\" ~ \"Paackland\",\n           location == \"City of South Paackland\" ~ \"South Paackland\",\n           TRUE ~ location  # Keep original value if none of the above conditions are met\n         ))\n\n# Join with mc2_nodes to get the company information\ntransponder_ping_df &lt;- transponder_pings %&gt;%\n  inner_join(mc2_nodes %&gt;% select(id, company), by = c(\"vessel\" = \"id\")) %&gt;% \n  mutate(date =ping_date,\n         start_time = time)\n\n# Calculate end_time by vessel\ndata &lt;- transponder_ping_df %&gt;%\n  group_by(vessel) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-05-01\") & date &lt;= as.Date(\"2035-05-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor) \n\n\n\n# Filter data and sort by vessel and date\nfiltered_data &lt;- data %&gt;%\n  filter(vessel %in% c(\"snappersnatcher7be\",\"roachrobberdb6\",\"albacoreangler47d\",\"costasmeraldaac7\",\"kingfishcapturerbe7\"))%&gt;%\n  arrange(vessel, date)\n\n# Create the Plotly plot with initial markers and labels\nplot &lt;- plot_ly() %&gt;%\n  add_markers(data = filtered_data, x = ~date, y = ~location_num, color = ~location_factor, \n              type = 'scatter', mode = 'markers+text', text = ~location, textposition = 'top center', hoverinfo = 'text')\n\n# Add lines for each vessel and set initial visibility to FALSE\nvessel_list &lt;- unique(filtered_data$vessel)\nvisibility_list &lt;- lapply(vessel_list, function(v) FALSE)\n\nfor (v in vessel_list) {\n  vessel_data &lt;- filtered_data %&gt;% filter(vessel == v)\n  plot &lt;- plot %&gt;%\n    add_lines(data = vessel_data, x = ~date, y = ~location_num, \n              name = v, visible = FALSE, hoverinfo = 'none')\n}\n\n# Create dropdown buttons for each vessel\nbuttons &lt;- lapply(seq_along(vessel_list), function(i) {\n  visibility &lt;- c(TRUE, rep(FALSE, length(vessel_list)))\n  visibility[i + 1] &lt;- TRUE  # Add 1 because the first element is for the markers\n  list(\n    method = \"update\",\n    args = list(\n      list(visible = visibility),\n      list(title = paste(\"Path of\", vessel_list[i], \"Over Time\"))\n    ),\n    label = vessel_list[i]\n  )\n})\n\n# Add layout settings with dropdown menu\nplot &lt;- plot %&gt;%\n  layout(title = \"Path of Vessel Locations Over Time\",\n         xaxis = list(title = \"Time\"),\n         yaxis = list(title = \"Location\"),\n         hovermode = 'closest',\n         updatemenus = list(\n           list(\n             type = \"dropdown\",\n             direction = \"down\",\n             buttons = buttons,\n             showactive = TRUE\n           )\n         )\n  )\n\nplot\n\n\n\n\n\n\n\ntest &lt;-  unique(filtered_data$vessel)\ntest\n\n[1] \"albacoreangler47d\"   \"costasmeraldaac7\"    \"kingfishcapturerbe7\"\n[4] \"roachrobberdb6\"      \"snappersnatcher7be\" \n\n\n\n# Ensure data is arranged\nfiltered_data &lt;- data %&gt;%\n  arrange(vessel, date)\n\n# Create the Plotly plot with initial markers and labels\nplot &lt;- plot_ly() %&gt;%\n  add_markers(data = filtered_data, x = ~date, y = ~location_num, color = ~location_factor, \n              type = 'scatter', mode = 'markers+text', text = ~location, textposition = 'top center', hoverinfo = 'text')\n\n# Add lines for each vessel and set initial visibility to FALSE\nvessel_list &lt;- unique(filtered_data$vessel)\nfor (v in vessel_list) {\n  vessel_data &lt;- filtered_data[filtered_data$vessel == v, ]\n  plot &lt;- plot %&gt;%\n    add_lines(data = vessel_data, x = ~date, y = ~location_num, \n              name = v, visible = FALSE, hoverinfo = 'none')\n}\n\n# Create dropdown buttons for each company\nbuttons &lt;- lapply(unique(filtered_data$company), function(company) {\n  company_vessels &lt;- filtered_data$vessel[filtered_data$company == company]\n  visibility &lt;- sapply(vessel_list, function(v) v %in% company_vessels)\n  visibility &lt;- c(TRUE, visibility)  # Ensure markers are always visible\n  list(\n    method = \"update\",\n    args = list(\n      list(visible = visibility),\n      list(title = paste(\"Path of Vessels in Company\", company, \"Over Time\"))\n    ),\n    label = company\n  )\n})\n\n# Add layout settings with dropdown menu\nplot &lt;- plot %&gt;%\n  layout(title = \"Path of Vessel Locations Over Time\",\n         xaxis = list(title = \"Time\"),\n         yaxis = list(title = \"Location\"),\n         hovermode = 'closest',\n         updatemenus = list(\n           list(\n             type = \"dropdown\",\n             direction = \"down\",\n             buttons = buttons\n           )\n         )\n  )\n\nplot\n\n\n\n\n\n\n\n# Validate geometries\ngeo_data &lt;- geo_data %&gt;%\n  st_make_valid()\n\n# Join node data\nmc2_nodes_geo &lt;- data %&gt;%\n  left_join(geo_data, by = c(\"location\" = \"id\"))\n\n# Convert the resulting data frame to sf object\nmc2_nodes_geo_sf &lt;- st_as_sf(mc2_nodes_geo)\n\n# Extract coordinates for plotting for geometries\nmc2_nodes_geo_sf &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2])%&gt;%\n  filter(vessel ==\"snappersnatcher7be\")\n\n\ntmap_mode(\"plot\")\n\ngeo_data &lt;- st_as_sf(geo_data, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\n# Add columns to mark origin and destination\nmc2_nodes_geo_sf_start_ &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(point_type = case_when(\n    row_number() == 1 ~ \"origin\",\n    row_number() == n() ~ \"destination\",\n    TRUE ~ \"middle\"\n  ))\n\n# Create the tmap with labels\ntm_shape(geo_data) +\n  tm_borders(col = \"black\", alpha = 0.5) +  # Optional: borders around each shape\n  tm_symbols(col = \"red\", size = 0.2) +  # Plot nodes\n  tm_layout(main.title = \"Vessel Trajectories\",\n            main.title.size = 0.8) +\n  tmap_style(\"watercolor\")  # Using the watercolor style for background\n\n\n\nggplot() +\n  geom_sf(data = geo_data, aes(geometry = geometry), color = \"red\", size = 1) +  # Plot nodes\n  geom_path(data = mc2_nodes_geo_sf, aes(x = Longitude, y = Latitude, group = vessel), color = \"blue\", size = 1) +  # Plot paths\n  geom_text(data = mc2_nodes_geo_sf, aes(x = Longitude, y = Latitude, label = location), size = 3, vjust = -1) +  # Add labels\n  scale_color_manual(values = c(\"origin\" = \"green\", \"destination\" = \"red\", \"middle\" = \"blue\")) +  # Colors for different points\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Vessel Trajectories\") +\n  coord_sf() +  # Use coord_sf for spatial data\n  theme_minimal()  # Minimal theme\n\n\n\n\n\n#### Last HarborReport of SouthSeafood Express Corp\"\ndate_caught &lt;- max(harboureport_culprit$harboreporting_date)\nprint(date_caught)\n\n[1] \"2035-05-09\"\n\n\n\"SouthSeafood Express Corp\"was likely caught just after \"2035-05-09\" as that happened to be it’s last harbor report."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-microsoft-access-database",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-microsoft-access-database",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "Importing Microsoft Access database",
    "text": "Importing Microsoft Access database\n\nThe data set\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\nImporting database into R\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess('data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\nData Preparation\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_rds(\"data/rds/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\nBullet chart in ggplot2\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "Plotting sparklines using ggplot2",
    "text": "Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\nPreparing the data\n\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)\n\n\n\nsparklines in ggplot2\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "Static Information Dashboard Design: gt and gtExtras methods",
    "text": "Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\nPlotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n  \n    \n      Product\n      current\n    \n  \n  \n    Amaretto\n          \n    Caffe Latte\n          \n    Caffe Mocha\n          \n    Chamomile\n          \n    Colombian\n          \n    Darjeeling\n          \n    Decaf Espresso\n          \n    Decaf Irish Cream\n          \n    Earl Grey\n          \n    Green Tea\n          \n    Lemon\n          \n    Mint\n          \n    Regular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#sparklines-gtextras-method",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "sparklines: gtExtras method",
    "text": "sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == \"2013\") %&gt;%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup()\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   &lt;chr&gt;             &lt;list&gt;         \n 1 Amaretto          &lt;dbl [12]&gt;     \n 2 Caffe Latte       &lt;dbl [12]&gt;     \n 3 Caffe Mocha       &lt;dbl [12]&gt;     \n 4 Chamomile         &lt;dbl [12]&gt;     \n 5 Colombian         &lt;dbl [12]&gt;     \n 6 Darjeeling        &lt;dbl [12]&gt;     \n 7 Decaf Espresso    &lt;dbl [12]&gt;     \n 8 Decaf Irish Cream &lt;dbl [12]&gt;     \n 9 Earl Grey         &lt;dbl [12]&gt;     \n10 Green Tea         &lt;dbl [12]&gt;     \n11 Lemon             &lt;dbl [12]&gt;     \n12 Mint              &lt;dbl [12]&gt;     \n13 Regular Espresso  &lt;dbl [12]&gt;     \n\n\n\nPlotting Coffechain Sales report\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\nAdding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n    \n  \n  \n    Amaretto\n1016\n1210\n1,119.00\n    Caffe Latte\n1398\n1653\n1,528.33\n    Caffe Mocha\n3322\n3828\n3,613.92\n    Chamomile\n2967\n3395\n3,217.42\n    Colombian\n5132\n5961\n5,457.25\n    Darjeeling\n2926\n3281\n3,112.67\n    Decaf Espresso\n3181\n3493\n3,326.83\n    Decaf Irish Cream\n2463\n2901\n2,648.25\n    Earl Grey\n2730\n3005\n2,841.83\n    Green Tea\n1339\n1476\n1,398.75\n    Lemon\n3851\n4418\n4,080.83\n    Mint\n1388\n1669\n1,519.17\n    Regular Espresso\n890\n1218\n1,023.42\n  \n  \n  \n\n\n\n\n\n\nCombining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\n\n\nPlotting the updated data.table\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n    Colombian\n5132\n5961\n5457.250\n          5.5K\n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n    Lemon\n3851\n4418\n4080.833\n          4.4K\n    Mint\n1388\n1669\n1519.167\n          1.5K\n    Regular Espresso\n890\n1218\n1023.417\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nCombining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\nsales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n      Actual\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n          \n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n          \n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n          \n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n          \n    Colombian\n5132\n5961\n5457.250\n          5.5K\n          \n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n          \n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n          \n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n          \n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n          \n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n          \n    Lemon\n3851\n4418\n4080.833\n          4.4K\n          \n    Mint\n1388\n1669\n1519.167\n          1.5K\n          \n    Regular Espresso\n890\n1218\n1023.417\n          1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on Exercise 7: Information Dashboard Design: R methods",
    "section": "Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\nPlotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding points and labels\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding reference line\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding bandline\nInstead adding reference line, bandline can be added by using the bandline argument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "Getting started",
    "text": "Getting started\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse, odbc, RODBC, rmarkdown)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactable provides functions to create interactive data tables for R, based on the React Table library and made with reactR.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "Importing Microsoft Access database",
    "text": "Importing Microsoft Access database\n\nThe data set\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\nImporting database into R\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess('data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\nData Preparation\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_rds(\"data/rds/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\nBullet chart in ggplot2\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "Plotting sparklines using ggplot2",
    "text": "Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\nPreparing the data\n\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)\n\n\n\nsparklines in ggplot2\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "Static Information Dashboard Design: gt and gtExtras methods",
    "text": "Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\nPlotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n  \n    \n      Product\n      current\n    \n  \n  \n    Amaretto\n          \n    Caffe Latte\n          \n    Caffe Mocha\n          \n    Chamomile\n          \n    Colombian\n          \n    Darjeeling\n          \n    Decaf Espresso\n          \n    Decaf Irish Cream\n          \n    Earl Grey\n          \n    Green Tea\n          \n    Lemon\n          \n    Mint\n          \n    Regular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "sparklines: gtExtras method",
    "text": "sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == \"2013\") %&gt;%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup()\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   &lt;chr&gt;             &lt;list&gt;         \n 1 Amaretto          &lt;dbl [12]&gt;     \n 2 Caffe Latte       &lt;dbl [12]&gt;     \n 3 Caffe Mocha       &lt;dbl [12]&gt;     \n 4 Chamomile         &lt;dbl [12]&gt;     \n 5 Colombian         &lt;dbl [12]&gt;     \n 6 Darjeeling        &lt;dbl [12]&gt;     \n 7 Decaf Espresso    &lt;dbl [12]&gt;     \n 8 Decaf Irish Cream &lt;dbl [12]&gt;     \n 9 Earl Grey         &lt;dbl [12]&gt;     \n10 Green Tea         &lt;dbl [12]&gt;     \n11 Lemon             &lt;dbl [12]&gt;     \n12 Mint              &lt;dbl [12]&gt;     \n13 Regular Espresso  &lt;dbl [12]&gt;     \n\n\n\nPlotting Coffechain Sales report\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\nAdding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n    \n  \n  \n    Amaretto\n1016\n1210\n1,119.00\n    Caffe Latte\n1398\n1653\n1,528.33\n    Caffe Mocha\n3322\n3828\n3,613.92\n    Chamomile\n2967\n3395\n3,217.42\n    Colombian\n5132\n5961\n5,457.25\n    Darjeeling\n2926\n3281\n3,112.67\n    Decaf Espresso\n3181\n3493\n3,326.83\n    Decaf Irish Cream\n2463\n2901\n2,648.25\n    Earl Grey\n2730\n3005\n2,841.83\n    Green Tea\n1339\n1476\n1,398.75\n    Lemon\n3851\n4418\n4,080.83\n    Mint\n1388\n1669\n1,519.17\n    Regular Espresso\n890\n1218\n1,023.42\n  \n  \n  \n\n\n\n\n\n\nCombining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\n\n\nPlotting the updated data.table\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n    Colombian\n5132\n5961\n5457.250\n          5.5K\n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n    Lemon\n3851\n4418\n4080.833\n          4.4K\n    Mint\n1388\n1669\n1519.167\n          1.5K\n    Regular Espresso\n890\n1218\n1023.417\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nCombining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\nsales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n      Actual\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n          \n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n          \n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n          \n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n          \n    Colombian\n5132\n5961\n5457.250\n          5.5K\n          \n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n          \n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n          \n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n          \n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n          \n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n          \n    Lemon\n3851\n4418\n4080.833\n          4.4K\n          \n    Mint\n1388\n1669\n1519.167\n          1.5K\n          \n    Regular Espresso\n890\n1218\n1023.417\n          1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\nPlotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding points and labels\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding reference line\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding bandline\nInstead adding reference line, bandline can be added by using the bandline argument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "Do It Yourself",
    "text": "Do It Yourself\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Cycle Plot",
    "text": "Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nSrep 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-suspicious-trajectories",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-2-part-4-suspicious-trajectories",
    "title": "Take Home Exercise 3",
    "section": "Task 2 (part 4) : Suspicious Trajectories",
    "text": "Task 2 (part 4) : Suspicious Trajectories\nIn this section, we conduct an analysis of vessel trajectories to identify suspicious activities, particularly focusing on the operations of SouthSeafood Express Corp.\nTo begin, we extract transponder ping data, which provides information on vessel movements. We preprocess this data, assigning numeric values to locations and filtering out irrelevant areas such as Haacklee, Himark, Port Grove, Lomark, Paackland, and South Paackland.\n\n\nShow the code\n# Extract transponder ping data for vessel movements\ntransponder_pings &lt;- mc2_links_prep %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\") %&gt;%\n  rename(location = source, vessel = target, ping_date = ping_date) %&gt;%\n  mutate(ping_id = row_number(),  # Add a unique identifier for each row\n         location = case_when(\n           location == \"City of Haacklee\" ~ \"Haacklee\",\n           location == \"City of Himark\" ~ \"Himark\",\n           location == \"City of Port Grove\" ~ \"Port Grove\",\n           location == \"City of Lomark\" ~ \"Lomark\",\n           location == \"City of Paackland\" ~ \"Paackland\",\n           location == \"City of South Paackland\" ~ \"South Paackland\",\n           TRUE ~ location  # Keep original value if none of the above conditions are met\n         ))\n\n\nNext, we calculate the start and end times for each vessel’s journey, which allows us to determine the duration and locations visited by each vessel.\n\n\nShow the code\n# Join with mc2_nodes to get the company information\ntransponder_ping_df &lt;- transponder_pings %&gt;%\n  inner_join(mc2_nodes %&gt;% select(id, company), by = c(\"vessel\" = \"id\")) %&gt;% \n  mutate(date =ping_date,\n         start_time = time)\n\n# Calculate end_time by vessel\ndata &lt;- transponder_ping_df %&gt;%\n  group_by(vessel) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-05-01\") & date &lt;= as.Date(\"2035-05-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n\nAfter preprocessing, we plot the trajectories of two vessels, “snappersnatcher7be” and “roachrobberdb6,” using ggplot. In the ggplot visualization, we showcase the vessels’ paths over time, along with location labels and customized color coding for each vessel. ggrepel was used to ensure that the labels not overlap.\n\n\nShow the code\ncombined_data &lt;- data %&gt;%\n  filter(vessel %in% c(\"snappersnatcher7be\", \"roachrobberdb6\")) %&gt;%\n  arrange(vessel, date)\n\n# Create a line plot of vessel location over time\nggplot(combined_data, aes(x = date, y = location_num, color = vessel)) +\n  geom_line() +\n  geom_point(size = 2) +  # Add points for each location\n  geom_text_repel(aes(label = location), size = 3) +  # Add labels with repelling\n  labs(title = \"SouthSeafood Express Corp Vessel's  Trajectories Over Time\",\n       x = \"Time\", y = \"Location\", color = \"Vessel\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"snappersnatcher7be\" = \"blue\", \"roachrobberdb6\" = \"green\"))  # Define custom colors for each vessel\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant Observations\n\nThrough this visualization, we discerned a notable trend: both vessels frequently intersect at Nav3. This observation suggests a potential area for further investigation into the activities of SouthSeafood Express Corp. The consistent intersection of these vessels raises questions about the nature of their interactions at this location. This finding prompts us to delve deeper into the activities and operations of SouthSeafood Express Corp, as it may indicate coordinated movements or potential transshipment activities between the vessels. Further scrutiny of these intersecting points could uncover crucial insights into the company’s operational strategies and shed light on any illicit activities that may be occurring.\n\n\n\nIn the following section, we utilize several packages to prepare and process the data. We primarily use the sf package for handling spatial data, the dplyr package for data manipulation, and the ggplot2 package for data visualization. Additionally, we employ the tmap package to create interactive thematic maps.\nHere’s a summary of the technical steps:\nData Validation and Joining: We validate the geometries of the geographical data and join the node data with the geographical data based on the location identifier.\nConversion to sf Object: We convert the resulting data frame into an sf object using the st_as_sf function from the sf package.\nCoordinates Extraction: We extract coordinates for plotting the trajectories of the vessels “snappersnatcher7be” and “roachrobberdb6” separately using the st_coordinates function.\nData Combination: We combine the data for both vessels into a single data frame using the bind_rows function from the dplyr package.\n\n\nShow the code\n# Validate geometries\ngeo_data &lt;- geo_data %&gt;%\n  st_make_valid()\n\n# Join node data\nmc2_nodes_geo &lt;- data %&gt;%\n  left_join(geo_data, by = c(\"location\" = \"id\"))\n\n# Convert the resulting data frame to sf object\nmc2_nodes_geo_sf &lt;- st_as_sf(mc2_nodes_geo)\n\n# Extract coordinates for plotting for geometries\nsnappersnatcher7be_sf &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2]) %&gt;%\n  filter(vessel == \"snappersnatcher7be\")\n\nroachrobberdb6_sf &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2]) %&gt;%\n  filter(vessel == \"roachrobberdb6\")\n\n# Combine data for both vessels\ncombined_sf &lt;- bind_rows(snappersnatcher7be_sf, roachrobberdb6_sf)\n\n\nTmap Mode Setting: We set the tmap mode to “plot” using the tmap_mode function from the tmap package.\nMap Creation with tmap: We create a thematic map using tmap functions such as tm_shape, tm_borders, and tm_symbols. This map includes borders around each shape, symbols for nodes, and a watercolor style background.\nPlot Creation with ggplot: We create a ggplot with the geom_sf function to plot the geographical data, geom_path to plot the vessel trajectories, and geom_text to add labels to the plot. We also customize the plot aesthetics such as colors and legend titles using functions like scale_color_manual and labs.\n\n\nShow the code\n# Set tmap mode\ntmap_mode(\"plot\")\n\ngeo_data &lt;- st_as_sf(geo_data, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\n\n# Create the ggplot with the legend for vessels\nggplot() +\n  geom_sf(data = geo_data, aes(geometry = geometry), color = \"black\", size = 0.5, fill = NA) +  # Plot borders\n  geom_point(data = combined_sf, aes(x = Longitude, y = Latitude, color = vessel), size = 3) +  # Plot points\n  geom_path(data = combined_sf, aes(x = Longitude, y = Latitude, color = vessel, group = vessel), size = 1) +  # Plot paths\n  geom_text(data = combined_sf, aes(x = Longitude, y = Latitude, label = location), size = 3, vjust = -1) +  # Add labels\n  scale_color_manual(values = c(\"snappersnatcher7be\" = \"green\", \"roachrobberdb6\" = \"blue\")) +  # Colors for different vessels\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"SouthSeafood Express Corp Vessel Trajectories\", color = \"Vessel\") +  # Add legend title\n  coord_sf() +  # Use coord_sf for spatial data\n  theme_minimal()  # Mi"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-3",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-3",
    "title": "Take Home Exercise 3",
    "section": "Task 3:",
    "text": "Task 3:\nIn the previous analysis, we conducted an assessment of transshipment activities, which led us to identify SouthSeafood Express Corp as suspicious. This finding suggested a potential involvement in illegal fishing activities and we decided to analyze if other companies exhibit the same patterns.\n\n1. Defining Transshipment\n\nTransshipment refers to the transfer of cargo from one vessel to another while at sea. For our analysis, we define a transshipment event as occurring when multiple vessels from the same company are present at the same location on the same date, excluding cities\n\n\n\n2. Process\n\nIdentified transshipment points by grouping the data and filtering for locations with multiple vessels.\nCounted transshipment instances by grouping the filtered data by company and date, ensuring that multiple events on the same day are counted as one.\nEvaluated the results by summarizing the number of unique transshipment days for each company.\n\n\n\nShow the code\n# Step 1: Firstly, let's recreate the dataframe earlier but with a larger date range\ndata &lt;- transponder_ping_df %&gt;%\n  group_by(vessel) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-02-01\") & date &lt;= as.Date(\"2035-05-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n\n\n# Step 2: Identify transshipment points\nexcluded_locations &lt;- c(\"Haacklee\", \"Himark\", \"Port Grove\", \"Lomark\", \"Paackland\", \"South Paackland\")\n\ntransshipment_data &lt;- data %&gt;%\n  filter(!location %in% excluded_locations) %&gt;%\n  group_by(company, date, location) %&gt;%\n  summarise(vessels_at_location = n_distinct(vessel), .groups = 'drop') %&gt;%\n  filter(vessels_at_location &gt; 1)\n\n# Step 3: Count transshipment instances grouped by company, considering each day with transshipment as one instance\ntransshipment_count &lt;- transshipment_data %&gt;%\n  group_by(company, date) %&gt;%\n  summarise(transshipment = n_distinct(date), .groups = 'drop') %&gt;%\n  group_by(company) %&gt;%\n  summarise(transshipment_days = n(), .groups = 'drop')\n\n\nThe transshipment_count data frame is used for creating the column chart.\nPlotting the Column Chart: We use ggplot() to initiate the plotting process. Inside aes(), we define the aesthetic mappings, where x represents the companies reordered by the number of transshipment days, y represents the number of transshipment days, and fill is used to differentiate between companies. We then add geom_col() to create the column chart.\nLabels and Titles: We add appropriate labels and titles to the plot using labs(), specifying the title, x-axis label, and y-axis label.\nTheme Settings: We adjust the theme of the plot using theme_minimal() to achieve a clean and minimalist appearance. Additionally, we rotate the x-axis text labels by 90 degrees using theme(axis.text.x = element_text(angle = 90, hjust = 1)) to prevent overlap.\nLegend: We remove the legend for the fill aesthetic using guides(fill = “none”) since the fill color does not convey additional information in this specific chart.\n\n\nShow the code\n# Create a column chart\nggplot(transshipment_count, aes(x = reorder(company, -transshipment_days), y = transshipment_days, fill = company)) +\n  geom_col() +\n  labs(title = \"Number of Transshipment Days by Company\",\n       x = \"Company\",\n       y = \"Transshipment Days\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant Observations\n\nApproximately 45 companies have shown indications of engaging in transshipment activities. Given that transshipment often correlates with illegal fishing practices, this suggests that these 45 companies may be violating fishing regulations."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-4",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#task-4",
    "title": "Take Home Exercise 3",
    "section": "Task 4:",
    "text": "Task 4:\nIn this section, we recreate the data and transshipment_data by processing the dataframe (transponder_ping_df) to analyze transshipment activities of vessels, this time for a larger date range. We aim to split the data into two periods: before and after SouthSeafood Express Corp was caught, likely around May 16, 2035.\nThe goal is to identify new companies involved in transshipment activities after the catch date by comparing the companies from both periods, highlighting potential new entrants to transshipment following the crackdown on SouthSeafood Express Corp.\n\n\n\n\n\n\nNote\n\n\n\nOther considerations\nHowver, since it is unlikely that companies restart illegal operations immediately after they are caught, we set the cutoff date to two months after SouthSeafood Express Corp was caught instead as 2035-07-12.\n\n\n\n\nShow the code\ndata &lt;- transponder_ping_df %&gt;%\n  group_by(vessel) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-02-01\") & date &lt;= as.Date(\"2035-10-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n\n\n# Step 2: Identify transshipment points\nexcluded_locations &lt;- c(\"Haacklee\", \"Himark\", \"Port Grove\", \"Lomark\", \"Paackland\", \"South Paackland\")\n\ntransshipment_data &lt;- data %&gt;%\n  filter(!location %in% excluded_locations) %&gt;%\n  group_by(company, date, location) %&gt;%\n  summarise(vessels_at_location = n_distinct(vessel), .groups = 'drop') %&gt;%\n  filter(vessels_at_location &gt; 1)\n\n\n\n# Filter transshipment data after the date when SouthSeafood Express Corp was caught\nafter_catch_date_and2months &lt;- transshipment_data %&gt;%\n  filter(date &gt;= as.Date(\"2035-07-12\"))  # Adjust the date as per your data\n\n# Identify unique companies involved in transshipment after the catch date\nunique_companies_after_catch &lt;- after_catch_date_and2months %&gt;%\n  distinct(company)\n\n# Filter transshipment data before the catch date\nbefore_catch_date_and2months &lt;- transshipment_data %&gt;%\n  filter(date &lt; as.Date(\"2035-07-11\"))  # Adjust the date as per your data\n\n# Check if any of the companies after the catch date are new\nnew_companies &lt;- unique_companies_after_catch %&gt;%\n  filter(!company %in% before_catch_date_and2months$company)\n\n# Print new companies starting transshipment after SouthSeafood Express Corp was caught\nprint(new_companies)\n\n\n# A tibble: 2 × 1\n  company               \n  &lt;chr&gt;                 \n1 Tainamarine Fishing Co\n2 Taylor-Sawyer         \n\n\n\n\nShow the code\n# Step 1: Filter transshipment data for the new vessels found\nnew_vessels_transshipment &lt;- transshipment_data %&gt;%\n  filter(company %in% new_companies$company) %&gt;%\n  group_by(company, date) %&gt;%\n  summarise(transshipment = n_distinct(date), .groups = 'drop') %&gt;%\n  group_by(company) %&gt;%\n  summarise(transshipment_days = n(), .groups = 'drop')\n\n\n\n\n# Create a column chart\nggplot(new_vessels_transshipment, aes(x = reorder(company, -transshipment_days), y = transshipment_days, fill = company)) +\n  geom_col() +\n  labs(title = \"Number of Transshipment Days by Company\",\n       x = \"Company\",\n       y = \"Transshipment Days\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  guides(fill = \"none\")\n\n\n\n\n\nWe have identified two potential companies that might be the same entity as SouthSeafood Express Corp, which was caught red-handed and likely restarted their illegal fishing operations. These companies are Tainamarine Fishing Co and Taylor-Sawyer, both of which are found to be of suspicious of transhippment activities and also began operations within 2-3 months after SouthSeafood Express Corp was apprehended.\nAmong them, Tainamarine Fishing Co seemed to be the most likely suspect as the two vessels belonging to it swimmingsafely92d and posiedonsparadise7e6 possesses the same tonnage and length_overall as snappersnatcher7be and roachrobberdb6 respectively.\n\ninfo &lt;- mc2_nodes %&gt;%\n  filter(company %in% c(\"Tainamarine Fishing Co\", \"SouthSeafood Express Corp\"))\n\n# Select the relevant columns for tonnage and length_overall\ninfo %&gt;%\n  select(id, company, tonnage, length_overall)\n\n# A tibble: 4 × 4\n  id                   company                   tonnage length_overall\n  &lt;chr&gt;                &lt;chr&gt;                       &lt;dbl&gt;          &lt;dbl&gt;\n1 snappersnatcher7be   SouthSeafood Express Corp     100             20\n2 swimmingsafely92d    Tainamarine Fishing Co        100             20\n3 roachrobberdb6       SouthSeafood Express Corp   11700            130\n4 posiedonsparadise7e6 Tainamarine Fishing Co      11700            130\n\n\nIn the next section, we proceeded further to investigate Tainamarine Fishing Co by plotting its vessel trajectories over time. This in turn led to some interesting findings.\n\n\nShow the code\ndata &lt;- transponder_ping_df %&gt;%\n  group_by(vessel) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-08-05\") & date &lt;= as.Date(\"2035-08-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n  \ncombined_data &lt;- data %&gt;%\n  filter(company == \"Tainamarine Fishing Co\")\n\n# Create a line plot of vessel location over time\nggplot(combined_data, aes(x = date, y = location_num, color = vessel)) +\n  geom_line() +\n  geom_point(size = 2) +  # Add points for each location\n  geom_text_repel(aes(label = location), size = 3) +  # Add labels with repelling\n  labs(title = \"Vessel Trajectories Over Time by Company\", x = \"Time\", y = \"Location\", color = \"Vessel\") +\n  theme_minimal() \n\n\n\n\n\nFrom the visualization below, it seems that Tainamarine Fishing Co’s vessel trajectories is very similar to SouthSeafood Express Corp vessels and is very likely the same entity which was caught fishing illegally earlier.\n\n\nShow the code\n# Group the data by company and vessel\n\n# Join node data\nmc2_nodes_geo &lt;- combined_data %&gt;%\n  left_join(geo_data, by = c(\"location\" = \"id\"))\n\n# Convert the resulting data frame to sf object\nmc2_nodes_geo_sf &lt;- st_as_sf(mc2_nodes_geo)\n\n\ngrouped_data &lt;- mc2_nodes_geo_sf %&gt;%\n  filter(company == \"Tainamarine Fishing Co\") %&gt;%  \n  group_by(company, vessel) %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2])\n\n# Create a palette of colors\ncolors &lt;- rainbow(length(unique(grouped_data$vessel)))\n\n# Create a ggplot with the legend for vessels\nggplot() +\n  geom_sf(data = geo_data, aes(geometry = geometry), color = \"black\", size = 0.5, fill = NA) +  # Plot borders\n  geom_path(data = grouped_data, aes(x = Longitude, y = Latitude, color = vessel, group = vessel), size = 1) +  # Plot paths with different colors for each vessel\n  geom_point(data = grouped_data, aes(x = Longitude, y = Latitude, color = vessel), size = 3) +  # Plot points\n  geom_text(data = grouped_data, aes(x = Longitude, y = Latitude, label = location), size = 3, vjust = -1) +  # Add labels\n  scale_color_manual(values = colors) +  # Assign colors to vessels\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Vessel Trajectories by Company\", color = \"Vessel\") +  # Add legend title\n  coord_sf() +  # Use coord_sf for spatial data\n  theme_minimal()  # Minimal theme"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/shp/shp/Oceanus Geography.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/shp/shp/Oceanus Geography.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#learning-outcome",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "",
    "text": "By the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#the-data",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "The data",
    "text": "The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Creating a sf data frame from an aspatial data frame",
    "text": "Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "It all started with an interactive point symbol map",
    "text": "It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Lets make it proportional",
    "text": "Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Lets give it a different colour",
    "text": "Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#i-have-a-twin-brothers",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "I have a twin brothers :)",
    "text": "I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#all-about-tmap-package",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "All about tmap package",
    "text": "All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Geospatial data wrangling",
    "text": "Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-wrangling",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "Data wrangling",
    "text": "Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "Getting Started",
    "text": "Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-into-r",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nImporting Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\weipengten\\ISSS608\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\nImporting Attribute Data into R\nNext, we will import respopagsex2000to2018.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\nData Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\nCreating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\nPlotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\nMap Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "Reference",
    "text": "Reference\n\nAll about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\nGeospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\nData wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and loading packages\n\n\n\n\n\n\nYour turn\n\n\n\nUsing the steps you learned in previous lesson, install and load sf, tmap and tidyverse packages into R environment.\n\n\n\n\n\nShow the code\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n\nImporting data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\n\n\n\n\n\nDo it Yourself\n\n\n\nUsing appropriate sf function import NGA_wp.rds into R environment.\n\n\n\n\n\nShow the code\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "Basic Choropleth Mapping",
    "text": "Basic Choropleth Mapping\n\nVisualising distribution of non-functional water point\n\n\n\n\n\n\nYour turn\n\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA\n\n\n\n\n\nShow the code\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\n\n\nShow the code\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "Choropleth Map for Rates",
    "text": "Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\nDeriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\nPlotting map of rate\n\n\n\n\n\n\nYour turn\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\n\n\n\n\nShow the code\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "Extreme Value Maps",
    "text": "Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\nPercentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\nData Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\nWhy writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\nCreating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nA percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\nTest drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\nBox map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\nCreating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nTest drive the newly created function\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nBoxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/data/shp/shp/Oceanus Geography.html",
    "href": "In-class_Ex/In-class_Ex08/data/shp/shp/Oceanus Geography.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  }
]